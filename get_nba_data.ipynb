{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nba_api.stats.endpoints import leaguegamefinder\n",
    "# result = leaguegamefinder.LeagueGameFinder(team_id_nullable = 1610612738 ,  date_from_nullable='12/20/2019')\n",
    "# all_games = result.get_data_frames()[0]\n",
    "# all_games\n",
    "\n",
    "\n",
    "nba_teams = ['MIL', 'CHI', 'CHA', 'TOR', 'BOS', 'PHX', 'OKC', 'LAC', 'IND',\n",
    "       'BKN', 'MIN', 'UTA', 'SAS', 'DAL', 'CLE', 'NYK', 'POR', 'HOU',\n",
    "       'DEN', 'MEM', 'SAC', 'PHI',  'ATL', 'LAL', \n",
    "       'WAS', 'ORL', 'GSW', 'NOP', \n",
    "       'MIA', \n",
    "       'DET']\n",
    "nba_team_ids =[1610612749, 1610612766, 1610612738, 1610612746, 1610612754,\n",
    "       1610612750, 1610612741, 1610612742, 1610612762, 1610612759,\n",
    "       1610612739, 1610612752, 1610612761, 1610612760, 1610612757,\n",
    "       1610612751, 1610612745, 1610612756, 1610612743, 1610612755,\n",
    "       1610612737, 1610612763, 1610612764, 1610612744, 1610612740,\n",
    "       1610612753, 1610612747, 1610612758, 1610612748, 1610612765]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games =  138\n",
      "Len of file is  11824\n",
      "Len of file after trim is  11774\n"
     ]
    }
   ],
   "source": [
    "from nba_api.stats.endpoints import leaguegamefinder\n",
    "import pandas as pd\n",
    "# gamefinder = leaguegamefinder.LeagueGameFinder(  date_from_nullable='10/17/2017' , date_to_nullable='10/17/2019')\n",
    "gamefinder = leaguegamefinder.LeagueGameFinder(  date_from_nullable='01/22/2020')\n",
    "\n",
    "all_games = gamefinder.get_data_frames()[0]\n",
    "print('Number of games = ' , len(all_games))\n",
    "tmp = all_games[(all_games['GAME_DATE']<'2020-01-27')]\n",
    "# tmp = all_games[(all_games['GAME_DATE']<'2019-06-17')]\n",
    "with open('all_games.csv', 'a') as f:\n",
    "            tmp.to_csv(f, header=False, index=False) \n",
    "\n",
    "df = pd.read_csv('all_games.csv')\n",
    "print('Len of file is ', len(df))\n",
    "df.drop_duplicates(subset =['TEAM_ID','GAME_ID'],inplace=True)\n",
    "print('Len of file after trim is ', len(df))\n",
    "df.to_csv('all_games.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\212778050\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0021900675 0.0\n",
      "0021900669 0.02564102564102564\n",
      "0021900677 0.05128205128205128\n",
      "0021900676 0.07692307692307693\n",
      "0021900670 0.10256410256410256\n",
      "0021900672 0.1282051282051282\n",
      "0021900673 0.15384615384615385\n",
      "0021900674 0.1794871794871795\n",
      "0021900678 0.20512820512820512\n",
      "0021900671 0.23076923076923078\n",
      "0021900679 0.2564102564102564\n",
      "0021900666 0.28205128205128205\n",
      "0021900667 0.3076923076923077\n",
      "0021900668 0.3333333333333333\n",
      "0021900656 0.358974358974359\n",
      "0021900665 0.38461538461538464\n",
      "0021900663 0.41025641025641024\n",
      "0021900659 0.4358974358974359\n",
      "0021900661 0.46153846153846156\n",
      "0021900654 0.48717948717948717\n",
      "0021900655 0.5128205128205128\n",
      "0021900657 0.5384615384615384\n",
      "0021900658 0.5641025641025641\n",
      "0021900660 0.5897435897435898\n",
      "0021900664 0.6153846153846154\n",
      "0021900662 0.6410256410256411\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nba_api.stats.endpoints import playbyplayv2,boxscoreadvancedv2,boxscorescoringv2,boxscoretraditionalv2\n",
    "import pandas as pd\n",
    "\n",
    "all_games = gamefinder.get_data_frames()[0]\n",
    "all_games = all_games[all_games['TEAM_ID'].isin(nba_team_ids)]\n",
    "\n",
    "large_playbyplayv2_df           = pd.DataFrame([])\n",
    "large_boxscoreadvancedv2_df     = pd.DataFrame([])\n",
    "large_boxscorescoringv2_df      = pd.DataFrame([])\n",
    "large_boxscoretraditionalv2_df  = pd.DataFrame([])\n",
    "\n",
    "# print(len(list(set(all_games['GAME_ID'].unique().astype(int)) - set(games_parsed ))))\n",
    "counter = 0\n",
    "for game_id in all_games['GAME_ID'].unique():\n",
    "    \n",
    "    df_games_parsed = pd.read_csv('files/games_parsed.csv')\n",
    "    games_parsed = df_games_parsed['game_id'].unique()\n",
    "    if game_id not in games_parsed and int(game_id) not in games_parsed:\n",
    "        \n",
    "        print(game_id , float(counter)/float(len(all_games['GAME_ID'].unique())))\n",
    "        counter = counter + 1 \n",
    "        # get play by play\n",
    "        pbp = playbyplayv2.PlayByPlayV2(game_id)\n",
    "        pbp = pbp.get_data_frames()[0]\n",
    "        large_playbyplayv2_df = large_playbyplayv2_df.append(pbp)\n",
    "        with open('large_playbyplayv2_df.csv', 'a') as f:\n",
    "            large_playbyplayv2_df.to_csv(f, header=False, encoding = 'utf-8')\n",
    "        \n",
    "        # get boxscoretraditionalv2\n",
    "        bx = boxscoretraditionalv2.BoxScoreTraditionalV2(game_id)\n",
    "        bx = bx.get_data_frames()[0]\n",
    "        large_boxscoretraditionalv2_df = large_boxscoretraditionalv2_df.append(bx)\n",
    "        with open('large_boxscoretraditionalv2_df.csv', 'a') as f:\n",
    "            large_boxscoretraditionalv2_df.to_csv(f, header=False, encoding = 'utf-8', index=False)\n",
    "       \n",
    "        # get large_boxscorescoringv2_df\n",
    "        bx = boxscorescoringv2.BoxScoreScoringV2(game_id)\n",
    "        bx = bx.get_data_frames()[0]\n",
    "        large_boxscorescoringv2_df = large_boxscorescoringv2_df.append(bx)\n",
    "        with open('large_boxscorescoringv2_df.csv', 'a') as f:\n",
    "            large_boxscorescoringv2_df.to_csv(f, header=False, encoding = 'utf-8', index=False)\n",
    "        \n",
    "        # get boxscoreadvancedv2\n",
    "        bx = boxscoreadvancedv2.BoxScoreAdvancedV2(game_id)\n",
    "        bx = bx.get_data_frames()[0]\n",
    "        large_boxscoreadvancedv2_df = large_boxscoreadvancedv2_df.append(bx)\n",
    "        with open('large_boxscoreadvancedv2_df.csv', 'a') as f:\n",
    "            large_boxscoreadvancedv2_df.to_csv(f, header=False, encoding = 'utf-8', index=False)\n",
    "\n",
    "        with open('files/games_parsed.csv','a') as fd:\n",
    "            fd.write(game_id+'\\n')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import leaguedashplayershotlocations,playerdashptshotdefend,playerdashptshots,shotchartdetail\n",
    "\n",
    "# res = playerdashptshotdefend.PlayerDashPtShotDefend(player_id = '1628976' , team_id = '1610612749')\n",
    "# res = playerdashptshots.PlayerDashPtShots(player_id = '203507' , team_id = '1610612749')\n",
    "res = shotchartdetail.ShotChartDetail(player_id = '203507' , team_id = '1610612749')\n",
    "\n",
    "res.get_data_frames()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nba_teams = ['MIL', 'CHI', 'CHA', 'TOR', 'BOS', 'PHX', 'OKC', 'LAC', 'IND',\n",
    "       'BKN', 'MIN', 'UTA', 'SAS', 'DAL', 'CLE', 'NYK', 'POR', 'HOU',\n",
    "       'DEN', 'MEM', 'SAC', 'PHI',  'ATL', 'LAL', \n",
    "       'WAS', 'ORL', 'GSW', 'NOP', \n",
    "       'MIA', \n",
    "       'DET']\n",
    "nba_team_ids =[1610612749, 1610612766, 1610612738, 1610612746, 1610612754,\n",
    "       1610612750, 1610612741, 1610612742, 1610612762, 1610612759,\n",
    "       1610612739, 1610612752, 1610612761, 1610612760, 1610612757,\n",
    "       1610612751, 1610612745, 1610612756, 1610612743, 1610612755,\n",
    "       1610612737, 1610612763, 1610612764, 1610612744, 1610612740,\n",
    "       1610612753, 1610612747, 1610612758, 1610612748, 1610612765]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nba_teams_df = pd.DataFrame(nba_teams)\n",
    "dummy_nba_teams= pd.get_dummies(nba_team_ids, prefix ='team')\n",
    "\n",
    "\n",
    "df = pd.read_csv('large_boxscoretraditionalv2_df.csv')\n",
    "df=df[df['TEAM_ID'].isin(nba_team_ids)]\n",
    "df.drop_duplicates(subset = ['GAME_ID','PLAYER_ID'],inplace=True)\n",
    "df.dropna(subset=['MIN'],inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "df_g = pd.read_csv('all_games.csv')\n",
    "df_g.drop_duplicates(subset =['TEAM_ID','GAME_ID'],inplace=True)\n",
    "\n",
    "df_g.loc[df_g['WL']=='W','IsWin']=1\n",
    "df_g.loc[df_g['WL']=='L','IsWin']=0\n",
    "df_g['IsHome'] = (df_g['MATCHUP'].str.contains('vs.')).astype(int)\n",
    "df_g['Opposing_team'] = df_g['MATCHUP'].apply( lambda x: x.split(' ')[2])\n",
    "\n",
    "df_g=df_g[df_g['TEAM_ID'].isin(nba_team_ids)]\n",
    "team_abv_to_id_mapping = df_g[['TEAM_ABBREVIATION','TEAM_ID']].drop_duplicates().set_index('TEAM_ABBREVIATION')['TEAM_ID'].to_dict()\n",
    "df_g['Opposing_team_ID'] = df_g['Opposing_team'].apply(lambda x: team_abv_to_id_mapping[x] if x in team_abv_to_id_mapping else None )\n",
    "\n",
    "df_g=df_g[df_g['Opposing_team_ID'].isin(nba_team_ids)]\n",
    "\n",
    "# df_g=df_g[['GAME_ID','TEAM_ID','GAME_DATE']].drop_duplicates().dropna()\n",
    "df_g['GAME_DATE'] = pd.to_datetime(df_g['GAME_DATE'])\n",
    "\n",
    "df = df.merge(df_g, \n",
    "         how='inner',\n",
    "         left_on=['GAME_ID','TEAM_ID'],\n",
    "         right_on=['GAME_ID','TEAM_ID'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1180\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "204001 1 378\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "1626246 2 378\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "200826 3 378\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "1629760 4 378\n",
      "1629076 5 378\n",
      "pass\n",
      "pass\n",
      "203076 6 378\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "200765 7 378\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "1626162 8 378\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "1628413 9 378\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "202066 10 378\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "1629140 11 378\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "1628410 12 378\n",
      "203960 13 378\n",
      "1628388 14 378\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "1629752 15 378\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "200757 16 378\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "1628370 17 378\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "1629650 18 378\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "1627756 19 378\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "203459 20 378\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "201950 21 378\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "2772 22 378\n",
      "pass\n",
      "1628403 23 378\n",
      "1629660 24 378\n",
      "1629741 25 378\n",
      "pass\n",
      "1628405 26 378\n",
      "1629724 27 378\n",
      "1628982 28 378\n",
      "pass\n",
      "1629035 29 378\n",
      "1629627 30 378\n",
      "pass\n",
      "203085 31 378\n",
      "203914 32 378\n",
      "pass\n",
      "200752 33 378\n",
      "pass\n",
      "pass\n",
      "1629718 34 378\n",
      "1629003 35 378\n",
      "1629015 36 378\n",
      "203504 37 378\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "1629648 38 378\n",
      "1629663 39 378\n",
      "pass\n",
      "1626192 40 378\n",
      "203648 41 378\n",
      "101107 42 378\n",
      "203458 43 378\n",
      "pass\n",
      "1628987 44 378\n",
      "1629020 45 378\n",
      "1628427 46 378\n",
      "1626143 47 378\n",
      "pass\n",
      "202704 48 378\n",
      "203079 49 378\n",
      "201229 50 378\n",
      "203145 51 378\n",
      "pass\n",
      "1629657 52 378\n",
      "1629690 53 378\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n",
      "202334 54 378\n",
      "1628980 55 378\n",
      "1628372 56 378\n",
      "1629610 57 378\n",
      "pass\n",
      "1626187 58 378\n",
      "1629598 59 378\n",
      "1628392 60 378\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nba_api.stats.endpoints import leaguedashplayershotlocations,playerdashptshotdefend,playerdashptshots,shotchartdetail\n",
    "\n",
    "prev_ShotChartDetail_df = pd.read_csv('ShotChartDetail_v2.csv')\n",
    "\n",
    "a = prev_ShotChartDetail_df[['PLAYER_ID','TEAM_ID','run_date']].drop_duplicates()\n",
    "b = df[['PLAYER_ID','TEAM_ID']].drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "# filter minimum\n",
    "min_date = '2020-01-18'\n",
    "df=df[df['GAME_DATE']>min_date]\n",
    "print(len(df))\n",
    "\n",
    "max_date = 20200119\n",
    "count = 0\n",
    "for ix,row in df[['PLAYER_ID','TEAM_ID']].drop_duplicates().iterrows():\n",
    "    PLAYER_ID = row['PLAYER_ID']\n",
    "    TEAM_ID = row['TEAM_ID']\n",
    "    if (len(prev_ShotChartDetail_df[(prev_ShotChartDetail_df['PLAYER_ID']==PLAYER_ID)&\\\n",
    "                       (prev_ShotChartDetail_df['TEAM_ID']==TEAM_ID)])==0) |\\\n",
    "            (prev_ShotChartDetail_df[(prev_ShotChartDetail_df['PLAYER_ID']==PLAYER_ID)&\\\n",
    "                       (prev_ShotChartDetail_df['TEAM_ID']==TEAM_ID)]['run_date'].max() < max_date):\n",
    "        res = shotchartdetail.ShotChartDetail(player_id = PLAYER_ID ,\n",
    "                                              team_id = TEAM_ID,\n",
    "                                              date_from_nullable='01/19/2020',\n",
    "                                              date_to_nullable = '01/27/2020',\n",
    "                                             context_measure_simple='FGA')\n",
    "        ShotChartDetail_df = res.get_data_frames()[0]\n",
    "        ShotChartDetail_df['run_date'] = max_date\n",
    "        with open('ShotChartDetail_v2.csv', 'a') as f:\n",
    "                ShotChartDetail_df.to_csv(f, header=False , index=False)\n",
    "        count = count + 1 \n",
    "        print(PLAYER_ID , count , len(df[['PLAYER_ID','TEAM_ID']].drop_duplicates()))\n",
    "    else:\n",
    "        print('pass')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
