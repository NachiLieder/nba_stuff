{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "def load_dfs( MAX_DATE = None , MIN_DATE = None):\n",
    "    nba_teams = ['MIL', 'CHI', 'CHA', 'TOR', 'BOS', 'PHX', 'OKC', 'LAC', 'IND',\n",
    "           'BKN', 'MIN', 'UTA', 'SAS', 'DAL', 'CLE', 'NYK', 'POR', 'HOU',\n",
    "           'DEN', 'MEM', 'SAC', 'PHI',  'ATL', 'LAL', \n",
    "           'WAS', 'ORL', 'GSW', 'NOP', \n",
    "           'MIA', \n",
    "           'DET']\n",
    "    nba_team_ids =[1610612749, 1610612766, 1610612738, 1610612746, 1610612754,\n",
    "           1610612750, 1610612741, 1610612742, 1610612762, 1610612759,\n",
    "           1610612739, 1610612752, 1610612761, 1610612760, 1610612757,\n",
    "           1610612751, 1610612745, 1610612756, 1610612743, 1610612755,\n",
    "           1610612737, 1610612763, 1610612764, 1610612744, 1610612740,\n",
    "           1610612753, 1610612747, 1610612758, 1610612748, 1610612765]\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    nba_teams_df = pd.DataFrame(nba_teams)\n",
    "    dummy_nba_teams= pd.get_dummies(nba_team_ids, prefix ='team')\n",
    "\n",
    "\n",
    "    df = pd.read_csv('large_boxscoretraditionalv2_df.csv')\n",
    "    df=df[df['TEAM_ID'].isin(nba_team_ids)]\n",
    "    df.drop_duplicates(subset = ['GAME_ID','PLAYER_ID'],inplace=True)\n",
    "    df.dropna(subset=['MIN'],inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    df_g = pd.read_csv('all_games.csv')\n",
    "    df_g.drop_duplicates(subset =['TEAM_ID','GAME_ID'],inplace=True)\n",
    "\n",
    "    df_g.loc[df_g['WL']=='W','IsWin']=1\n",
    "    df_g.loc[df_g['WL']=='L','IsWin']=0\n",
    "    df_g['IsHome'] = (df_g['MATCHUP'].str.contains('vs.')).astype(int)\n",
    "    df_g['Opposing_team'] = df_g['MATCHUP'].apply( lambda x: x.split(' ')[2])\n",
    "\n",
    "    df_g=df_g[df_g['TEAM_ID'].isin(nba_team_ids)]\n",
    "    team_abv_to_id_mapping = df_g[['TEAM_ABBREVIATION','TEAM_ID']].drop_duplicates().set_index('TEAM_ABBREVIATION')['TEAM_ID'].to_dict()\n",
    "    df_g['Opposing_team_ID'] = df_g['Opposing_team'].apply(lambda x: team_abv_to_id_mapping[x] if x in team_abv_to_id_mapping else None )\n",
    "\n",
    "    df_g=df_g[df_g['Opposing_team_ID'].isin(nba_team_ids)]\n",
    "\n",
    "    # df_g=df_g[['GAME_ID','TEAM_ID','GAME_DATE']].drop_duplicates().dropna()\n",
    "    df_g['GAME_DATE'] = pd.to_datetime(df_g['GAME_DATE'])\n",
    "    \n",
    "    if MAX_DATE is not None:\n",
    "        df_g = df_g[df_g['GAME_DATE']<MAX_DATE]\n",
    "    if MIN_DATE is not None:\n",
    "        df_g = df_g[df_g['GAME_DATE']>MIN_DATE]\n",
    "    # add balance scoring\n",
    "\n",
    "\n",
    "    df = df.merge(df_g, \n",
    "         how='inner',\n",
    "         left_on=['GAME_ID','TEAM_ID'],\n",
    "         right_on=['GAME_ID','TEAM_ID'])\n",
    "\n",
    "\n",
    "    pbp = pd.read_csv('large_playbyplayv2_df.csv', index_col=0)\n",
    "    pbp.drop_duplicates(subset=['GAME_ID','EVENTNUM','PERIOD'], inplace=True)\n",
    "\n",
    "\n",
    "    shot_chart_df =  pd.read_csv('ShotChartDetail_v2.csv')\n",
    "    shot_chart_df.drop_duplicates(subset=['GAME_ID','GAME_EVENT_ID'], inplace=True)\n",
    "    \n",
    "    \n",
    "    df_g['num_of_possessions'] = df_g.apply( lambda x: get_possessions_per_game_and_team(x,pbp), axis=1)\n",
    "    df_g.dropna(subset=['num_of_possessions'],inplace=True)\n",
    "    df_g['AdjustedPM'] = (df_g['PLUS_MINUS']/df_g['num_of_possessions'])*100\n",
    "    df_g['OffRating'] = (df_g['PTS']/df_g['num_of_possessions'])*100\n",
    "    df_g['EFG'] = (df_g['FGM'] + 0.5*df_g['FG3M'])/df_g['FGA']\n",
    "    df_g['AST_ratio'] = df_g['AST']*100/((df_g['FGA'])+(df_g['FTA']*0.44)+(df_g['AST'])+(df_g['AST']))\n",
    "    df_g['Opp_points'] = df_g['PTS'] + df_g['PLUS_MINUS']\n",
    "    df_g['Def_Rating'] = (df_g['Opp_points'] / df_g['num_of_possessions'])*100\n",
    "\n",
    "    ['AdjustedPM','OffRating','EFG','AST_ratio','Opp_points','Def_Rating']\n",
    "\n",
    "    print('done')\n",
    "    return df,df_g,pbp,shot_chart_df,team_abv_to_id_mapping\n",
    "\n",
    "df,df_g,pbp,shot_chart_df,team_abv_to_id_mapping = load_dfs(  MAX_DATE = '2020-01-01',MIN_DATE = '2018-11-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_possessions_per_game_and_team(row,pbp):\n",
    "    try:\n",
    "        GAME_ID = row['GAME_ID']\n",
    "        is_home = row['IsHome']\n",
    "        single_game = pbp[pbp['GAME_ID']==GAME_ID]\n",
    "        index_indicator = 'Home_EOP' if is_home==1 else 'Visitor_EOP'\n",
    "\n",
    "        single_game = single_game.sort_values('EVENTNUM')\n",
    "        single_game['Shift_HOMEDESCRIPTION'] = single_game['HOMEDESCRIPTION'].shift(-1)\n",
    "        single_game[['Shift_HOMEDESCRIPTION','HOMEDESCRIPTION']]\n",
    "        single_game.loc[(single_game['HOMEDESCRIPTION'].isnull()==False)&\n",
    "                        (single_game['Shift_HOMEDESCRIPTION'].isnull()==True)&\n",
    "                        (single_game['EVENTMSGTYPE'].isin([1,2,3,4,5,7,9])),'Home_EOP'] = 1\n",
    "        single_game['Home_EOP'].fillna(0,inplace=True)\n",
    "        single_game[['Shift_HOMEDESCRIPTION','HOMEDESCRIPTION','VISITORDESCRIPTION','Home_EOP']]\n",
    "\n",
    "        single_game['Shift_VISITORDESCRIPTION'] = single_game['VISITORDESCRIPTION'].shift(-1)\n",
    "        single_game[['Shift_VISITORDESCRIPTION','VISITORDESCRIPTION']]\n",
    "        single_game.loc[(single_game['VISITORDESCRIPTION'].isnull()==False)&\n",
    "                        (single_game['Shift_VISITORDESCRIPTION'].isnull()==True)&\n",
    "                        (single_game['EVENTMSGTYPE'].isin([1,2,3,4,5,7,9])),'Visitor_EOP'] = 1\n",
    "        single_game['Visitor_EOP'].fillna(0,inplace=True)\n",
    "        return single_game[['Home_EOP','Visitor_EOP']].sum().loc[index_indicator]\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1610612749\n",
      "1610612766\n",
      "1610612738\n",
      "1610612746\n",
      "1610612754\n",
      "1610612750\n",
      "1610612741\n",
      "1610612742\n",
      "1610612762\n",
      "1610612759\n",
      "1610612739\n",
      "1610612752\n",
      "1610612761\n",
      "1610612760\n",
      "1610612757\n",
      "1610612751\n",
      "1610612745\n",
      "1610612756\n",
      "1610612743\n",
      "1610612755\n",
      "1610612737\n",
      "1610612763\n",
      "1610612764\n",
      "1610612744\n",
      "1610612740\n",
      "1610612753\n",
      "1610612747\n",
      "1610612758\n",
      "1610612748\n",
      "1610612765\n"
     ]
    }
   ],
   "source": [
    "nba_teams = ['MIL', 'CHI', 'CHA', 'TOR', 'BOS', 'PHX', 'OKC', 'LAC', 'IND',\n",
    "       'BKN', 'MIN', 'UTA', 'SAS', 'DAL', 'CLE', 'NYK', 'POR', 'HOU',\n",
    "       'DEN', 'MEM', 'SAC', 'PHI',  'ATL', 'LAL', \n",
    "       'WAS', 'ORL', 'GSW', 'NOP', \n",
    "       'MIA', \n",
    "       'DET']\n",
    "nba_team_ids =[1610612749, 1610612766, 1610612738, 1610612746, 1610612754,\n",
    "       1610612750, 1610612741, 1610612742, 1610612762, 1610612759,\n",
    "       1610612739, 1610612752, 1610612761, 1610612760, 1610612757,\n",
    "       1610612751, 1610612745, 1610612756, 1610612743, 1610612755,\n",
    "       1610612737, 1610612763, 1610612764, 1610612744, 1610612740,\n",
    "       1610612753, 1610612747, 1610612758, 1610612748, 1610612765]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nba_teams_df = pd.DataFrame(nba_teams)\n",
    "dummy_nba_teams= pd.get_dummies(nba_team_ids, prefix ='team')\n",
    "\n",
    "sliding_window_num_of_games = 3\n",
    "\n",
    "large_df_of_sequences = pd.DataFrame([])\n",
    " \n",
    "# create the sliding window dataframe per team\n",
    "for team in nba_team_ids:\n",
    "    print(team)\n",
    "    x = df_g[df_g['TEAM_ID'] == team].sort_values('GAME_DATE').reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    dummy_curr_team = pd.get_dummies(x['TEAM_ID'], prefix ='team').reindex(columns = dummy_nba_teams.columns, fill_value=0)\n",
    "    dummy_curr_team.columns = ['curr_' + col for col in dummy_curr_team.columns]\n",
    "    team_indicator = dummy_curr_team.loc[0].values\n",
    "    \n",
    "    \n",
    "    list_team_indicator = list(team_indicator) \n",
    "    for ix,row in x[sliding_window_num_of_games:].iterrows():\n",
    "        tmp = x.loc[ix-sliding_window_num_of_games:ix]\n",
    "        \n",
    "        # add sequence of wins\n",
    "        list_of_sequence_of_wins = list(tmp['IsWin'].values[:-1])\n",
    "        new_cols = []\n",
    "        for game in range(sliding_window_num_of_games):\n",
    "                new_cols.insert(0,'{}_games_back_IsWin'.format(game + 1))\n",
    "        df_of_sequence_of_wins = pd.DataFrame([list_of_sequence_of_wins],columns=new_cols)\n",
    "        \n",
    "        # get team indicator\n",
    "        team_indicator = dummy_curr_team[0:1]\n",
    "        \n",
    "        # is at home\n",
    "        list_of_sequence_of_at_home = list(tmp['IsHome'].values)\n",
    "        new_cols = []\n",
    "        for game in range(sliding_window_num_of_games+1):\n",
    "                new_cols.insert(0,'{}_games_back_IsHome'.format(game + 1))\n",
    "        df_of_sequence_of_at_home = pd.DataFrame([list_of_sequence_of_at_home],columns=new_cols)\n",
    "        \n",
    "        # get opp team indicator \n",
    "        opp_dummy_teams = pd.get_dummies(tmp['Opposing_team_ID'].astype(int), prefix ='team').reindex(columns = dummy_nba_teams.columns, fill_value=0)\n",
    "        opp_dummy_teams.columns = ['opp_' + col for col in opp_dummy_teams.columns]\n",
    "        appended_list_of_encoded_opp_teams = list(itertools.chain(*opp_dummy_teams.values))\n",
    "        appended_df_of_encoded_opp_teams = pd.DataFrame([appended_list_of_encoded_opp_teams])\n",
    "        \n",
    "        \n",
    "        # add averages of categories\n",
    "        cols_to_calc = ['PTS','REB','AST','STL','BLK','TOV','PLUS_MINUS','FG3_PCT','FG_PCT','FT_PCT','num_of_possessions',\n",
    "                       'AdjustedPM','OffRating','EFG','AST_ratio','Opp_points','Def_Rating'\n",
    "                       ]\n",
    "        averages_of_categories_curr_team = tmp[cols_to_calc][:-1].mean().values\n",
    "        df_of_averages_of_categories_curr_team = pd.DataFrame([averages_of_categories_curr_team],columns =cols_to_calc)\n",
    "        \n",
    "        \n",
    "        # add shot area avgs for curr team\n",
    "        shot_index= ['Mid-Range', 'In The Paint (Non-RA)', 'Restricted Area',\n",
    "       'Above the Break 3', 'Left Corner 3', 'Right Corner 3']\n",
    "\n",
    "        shot_chart_df_for_tmp = shot_chart_df[(shot_chart_df['GAME_ID'].isin(tmp[:-1]['GAME_ID'].values))&\n",
    "                                 (shot_chart_df['TEAM_ID']==team)].groupby(\n",
    "                                    ['SHOT_ZONE_BASIC']).mean()['SHOT_MADE_FLAG'].reset_index()\n",
    "        shot_chart_df_for_tmp_reindex = shot_chart_df_for_tmp[['SHOT_ZONE_BASIC','SHOT_MADE_FLAG']].set_index('SHOT_ZONE_BASIC').reindex(shot_index).fillna(0)\n",
    "        shot_area_avgs = shot_chart_df_for_tmp_reindex.T.reset_index(drop=True)\n",
    "        \n",
    "        # add shot chart of opposing teams during window\n",
    "        shot_chart_df_for_tmp = shot_chart_df[(shot_chart_df['GAME_ID'].isin(tmp[:-1]['GAME_ID'].values))&\n",
    "                                 (shot_chart_df['TEAM_ID']!=team)].groupby(\n",
    "                                    ['SHOT_ZONE_BASIC']).mean()['SHOT_MADE_FLAG'].reset_index()\n",
    "        shot_chart_df_for_tmp_reindex = shot_chart_df_for_tmp[['SHOT_ZONE_BASIC','SHOT_MADE_FLAG']].set_index('SHOT_ZONE_BASIC').reindex(shot_index).fillna(0)\n",
    "        shot_area_avgs_opp = shot_chart_df_for_tmp_reindex.T.reset_index(drop=True)\n",
    "        \n",
    "        # add sequence of scores\n",
    "        list_of_sequence_of_wins = list(tmp['PTS'].values[:-1])\n",
    "        new_cols = []\n",
    "        for game in range(sliding_window_num_of_games):\n",
    "                new_cols.insert(0,'{}_games_back_PTS'.format(game + 1))\n",
    "        \n",
    "        df_of_sequence_of_scores = pd.DataFrame([list_of_sequence_of_wins],columns=new_cols)\n",
    "        \n",
    "        \n",
    "         # add averages of categories for past opponents\n",
    "        list_of_opp_ids = list(tmp['Opposing_team_ID'].unique())\n",
    "\n",
    "        x_opp = df_g[(df_g['TEAM_ID'].isin(list_of_opp_ids))&\n",
    "                    (df_g['GAME_DATE'] < tmp['GAME_DATE'].max())&\n",
    "                    (df_g['GAME_DATE'] >= tmp['GAME_DATE'].min())].sort_values('GAME_DATE').reset_index(drop=True)\n",
    "        tmp_opp = x_opp[-sliding_window_num_of_games:ix]\n",
    "        cols_to_calc = ['PTS','REB','AST','STL','BLK','TOV','PLUS_MINUS','FG3_PCT','FG_PCT','FT_PCT','num_of_possessions',\n",
    "                       'AdjustedPM','OffRating','EFG','AST_ratio','Opp_points','Def_Rating']\n",
    "        averages_of_categories_opp_team = tmp_opp[cols_to_calc].mean().values\n",
    "        df_of_averages_of_categories_opp_team = pd.DataFrame([averages_of_categories_opp_team],columns = cols_to_calc).reset_index(drop=True)\n",
    "        \n",
    "        # add sequence of pms\n",
    "        list_of_sequence_of_pm = list(tmp['PLUS_MINUS'].values)\n",
    "        new_cols = []\n",
    "        for game in range(sliding_window_num_of_games):\n",
    "                new_cols.insert(0,'{}_games_back_Plusminus'.format(game + 1))\n",
    "        new_cols.append('Y') \n",
    "        df_of_sequence_of_plusminus = pd.DataFrame([list_of_sequence_of_pm],columns=new_cols)\n",
    "        \n",
    "        \n",
    "        # add sequence of days between games\n",
    "        tmp['GAME_DATE'].diff().dt.days.dropna()\n",
    "        l = tmp['GAME_DATE'].diff().dt.days.dropna().values\n",
    "        l = [4 if sl >4 else sl for sl in l]\n",
    "        new_cols = []\n",
    "        for game in range(sliding_window_num_of_games):\n",
    "                new_cols.insert(0,'{}_games_back_PTS'.format(game + 1))\n",
    "\n",
    "        df_days_between = pd.DataFrame([l],columns=new_cols)\n",
    "\n",
    "        # start merging all together \n",
    "        # 1. wins\n",
    "        # 2. team indicator\n",
    "        # 3. at home indicator\n",
    "        # 4. TOV sequence\n",
    "#         print(len(team_indicator.columns),'team_indicator')\n",
    "#         print(len(df_of_sequence_of_wins.columns),'df_of_sequence_of_wins')\n",
    "#         print(len(df_of_sequence_of_at_home.columns),'df_of_sequence_of_at_home')\n",
    "#         print(len(appended_df_of_encoded_opp_teams.columns),'appended_df_of_encoded_opp_teams')\n",
    "#         print(len(df_of_averages_of_categories_curr_team.columns),'df_of_averages_of_categories_curr_team')\n",
    "#         print(len(shot_area_avgs.columns),'shot_area_avgs')\n",
    "#         print(len(shot_area_avgs_opp.columns),'shot_area_avgs_opp')\n",
    "        \n",
    "        df_all_features = team_indicator.merge(df_of_sequence_of_wins , how='inner' , left_index=True , right_index=True)\n",
    "        df_all_features = df_all_features.merge(df_of_sequence_of_at_home, how='inner' , left_index=True , right_index=True)\n",
    "        df_all_features = df_all_features.merge(appended_df_of_encoded_opp_teams, how='inner' , left_index=True , right_index=True)\n",
    "        df_all_features = df_all_features.merge(df_of_averages_of_categories_curr_team, how='inner' , left_index=True , right_index=True)\n",
    "        df_all_features = df_all_features.merge(shot_area_avgs, how='inner' , left_index=True , right_index=True)\n",
    "        df_all_features = df_all_features.merge(shot_area_avgs_opp, how='inner' , left_index=True , right_index=True)\n",
    "        df_all_features = df_all_features.merge(df_of_sequence_of_scores, how='inner' , left_index=True , right_index=True)\n",
    "        df_all_features = df_all_features.merge(df_of_averages_of_categories_opp_team, how='inner' , left_index=True , right_index=True)\n",
    "        df_all_features = df_all_features.merge(df_of_sequence_of_plusminus, how='inner' , left_index=True , right_index=True)\n",
    "        df_all_features = df_all_features.merge(df_days_between, how='inner' , left_index=True , right_index=True)\n",
    "\n",
    "        large_df_of_sequences = large_df_of_sequences.append(df_all_features)\n",
    "    \n",
    "large_df_of_sequences.dropna(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2215, 213)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_df_of_sequences.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 11.27 degrees.\n",
      "Accuracy: 97.48 %.\n",
      "Variable: AdjustedPM_x         Importance: 0.0432\n",
      "Variable: 1_games_back_IsHome  Importance: 0.0405\n",
      "Variable: FT_PCT_y             Importance: 0.0211\n",
      "Variable: FT_PCT_x             Importance: 0.0208\n",
      "Variable: Above the Break 3_x  Importance: 0.0194\n",
      "Variable: Above the Break 3_y  Importance: 0.0183\n",
      "Variable: Restricted Area_y    Importance: 0.0173\n",
      "Variable: 1_games_back_PTS_x   Importance: 0.0171\n",
      "Variable: FG3_PCT_x            Importance: 0.0167\n",
      "Variable: Mid-Range_x          Importance: 0.0167\n",
      "Variable: In The Paint (Non-RA)_y Importance: 0.0166\n",
      "Variable: TOV_x                Importance: 0.0164\n",
      "Variable: Restricted Area_x    Importance: 0.0164\n",
      "Variable: FG3_PCT_y            Importance: 0.0164\n",
      "Variable: AST_ratio_x          Importance: 0.0163\n",
      "Variable: In The Paint (Non-RA)_x Importance: 0.0163\n",
      "Variable: Mid-Range_y          Importance: 0.0159\n",
      "Variable: num_of_possessions_y Importance: 0.0159\n",
      "Variable: REB_x                Importance: 0.0157\n",
      "Variable: REB_y                Importance: 0.0157\n",
      "Variable: TOV_y                Importance: 0.0157\n",
      "Variable: 1_games_back_Plusminus Importance: 0.0156\n",
      "Variable: 2_games_back_PTS_x   Importance: 0.0155\n",
      "Variable: 3_games_back_Plusminus Importance: 0.0155\n",
      "Variable: 2_games_back_Plusminus Importance: 0.0155\n",
      "Variable: FG_PCT_x             Importance: 0.0151\n",
      "Variable: Left Corner 3_y      Importance: 0.015\n",
      "Variable: OffRating_y          Importance: 0.015\n",
      "Variable: Def_Rating_x         Importance: 0.0148\n",
      "Variable: AST_x                Importance: 0.0145\n",
      "Variable: BLK_x                Importance: 0.0142\n",
      "Variable: PTS_y                Importance: 0.0142\n",
      "Variable: EFG_x                Importance: 0.0141\n",
      "Variable: FG_PCT_y             Importance: 0.0141\n",
      "Variable: PLUS_MINUS_x         Importance: 0.014\n",
      "Variable: AST_ratio_y          Importance: 0.0139\n",
      "Variable: OffRating_x          Importance: 0.0138\n",
      "Variable: Right Corner 3_x     Importance: 0.0133\n",
      "Variable: num_of_possessions_x Importance: 0.0132\n",
      "Variable: STL_x                Importance: 0.013\n",
      "Variable: Left Corner 3_x      Importance: 0.0129\n",
      "Variable: 3_games_back_PTS_x   Importance: 0.0129\n",
      "Variable: Opp_points_x         Importance: 0.0125\n",
      "Variable: STL_y                Importance: 0.0125\n",
      "Variable: AdjustedPM_y         Importance: 0.0124\n",
      "Variable: BLK_y                Importance: 0.0123\n",
      "Variable: PTS_x                Importance: 0.012\n",
      "Variable: Right Corner 3_y     Importance: 0.0116\n",
      "Variable: EFG_y                Importance: 0.0115\n",
      "Variable: Opp_points_y         Importance: 0.0113\n",
      "Variable: Def_Rating_y         Importance: 0.0108\n",
      "Variable: AST_y                Importance: 0.0101\n",
      "Variable: PLUS_MINUS_y         Importance: 0.0091\n",
      "Variable:                  102 Importance: 0.008\n",
      "Variable:                  105 Importance: 0.0078\n",
      "Variable: 1_games_back_PTS_y   Importance: 0.0048\n",
      "Variable: curr_team_1610612739 Importance: 0.0046\n",
      "Variable: curr_team_1610612741 Importance: 0.0044\n",
      "Variable: 2_games_back_PTS_y   Importance: 0.0041\n",
      "Variable: 3_games_back_PTS_y   Importance: 0.0037\n",
      "Variable: curr_team_1610612743 Importance: 0.0033\n",
      "Variable: curr_team_1610612752 Importance: 0.003\n",
      "Variable:                   92 Importance: 0.0026\n",
      "Variable: curr_team_1610612749 Importance: 0.0024\n",
      "Variable:                   97 Importance: 0.0024\n",
      "Variable:                   90 Importance: 0.0022\n",
      "Variable:                   94 Importance: 0.0021\n",
      "Variable:                  119 Importance: 0.0021\n",
      "Variable: 4_games_back_IsHome  Importance: 0.002\n",
      "Variable: 2_games_back_IsHome  Importance: 0.002\n",
      "Variable: curr_team_1610612761 Importance: 0.0019\n",
      "Variable: 3_games_back_IsHome  Importance: 0.0019\n",
      "Variable:                  115 Importance: 0.0019\n",
      "Variable:                   91 Importance: 0.0017\n",
      "Variable:                   64 Importance: 0.0016\n",
      "Variable:                  109 Importance: 0.0016\n",
      "Variable:                  116 Importance: 0.0016\n",
      "Variable: curr_team_1610612745 Importance: 0.0015\n",
      "Variable: curr_team_1610612755 Importance: 0.0015\n",
      "Variable: curr_team_1610612766 Importance: 0.0015\n",
      "Variable:                   75 Importance: 0.0015\n",
      "Variable: curr_team_1610612754 Importance: 0.0014\n",
      "Variable:                   20 Importance: 0.0014\n",
      "Variable:                   54 Importance: 0.0014\n",
      "Variable:                   98 Importance: 0.0014\n",
      "Variable: curr_team_1610612744 Importance: 0.0013\n",
      "Variable: curr_team_1610612748 Importance: 0.0013\n",
      "Variable:                    8 Importance: 0.0013\n",
      "Variable:                   25 Importance: 0.0013\n",
      "Variable:                   76 Importance: 0.0013\n",
      "Variable: curr_team_1610612746 Importance: 0.0012\n",
      "Variable:                   27 Importance: 0.0012\n",
      "Variable:                   44 Importance: 0.0012\n",
      "Variable: curr_team_1610612738 Importance: 0.0011\n",
      "Variable:                   30 Importance: 0.0011\n",
      "Variable:                    6 Importance: 0.001\n",
      "Variable:                   67 Importance: 0.001\n",
      "Variable:                   77 Importance: 0.001\n",
      "Variable:                   93 Importance: 0.001\n",
      "Variable:                   95 Importance: 0.001\n",
      "Variable:                   96 Importance: 0.001\n",
      "Variable: curr_team_1610612742 Importance: 0.0009\n",
      "Variable:                    3 Importance: 0.0009\n",
      "Variable:                   48 Importance: 0.0009\n",
      "Variable:                   53 Importance: 0.0009\n",
      "Variable:                   58 Importance: 0.0009\n",
      "Variable:                   72 Importance: 0.0009\n",
      "Variable:                   73 Importance: 0.0009\n",
      "Variable:                  108 Importance: 0.0009\n",
      "Variable:                  114 Importance: 0.0009\n",
      "Variable: 1_games_back_IsWin   Importance: 0.0008\n",
      "Variable:                   10 Importance: 0.0008\n",
      "Variable:                   47 Importance: 0.0008\n",
      "Variable:                   57 Importance: 0.0008\n",
      "Variable:                   68 Importance: 0.0008\n",
      "Variable:                   81 Importance: 0.0008\n",
      "Variable:                   83 Importance: 0.0008\n",
      "Variable:                   86 Importance: 0.0008\n",
      "Variable:                   99 Importance: 0.0008\n",
      "Variable:                  106 Importance: 0.0008\n",
      "Variable:                  107 Importance: 0.0008\n",
      "Variable:                  118 Importance: 0.0008\n",
      "Variable: curr_team_1610612747 Importance: 0.0007\n",
      "Variable:                   19 Importance: 0.0007\n",
      "Variable:                   28 Importance: 0.0007\n",
      "Variable:                   31 Importance: 0.0007\n",
      "Variable:                   33 Importance: 0.0007\n",
      "Variable:                   41 Importance: 0.0007\n",
      "Variable:                   63 Importance: 0.0007\n",
      "Variable:                   80 Importance: 0.0007\n",
      "Variable:                  100 Importance: 0.0007\n",
      "Variable:                  103 Importance: 0.0007\n",
      "Variable: curr_team_1610612740 Importance: 0.0006\n",
      "Variable: curr_team_1610612762 Importance: 0.0006\n",
      "Variable: curr_team_1610612765 Importance: 0.0006\n",
      "Variable: 3_games_back_IsWin   Importance: 0.0006\n",
      "Variable: 2_games_back_IsWin   Importance: 0.0006\n",
      "Variable:                    4 Importance: 0.0006\n",
      "Variable:                   12 Importance: 0.0006\n",
      "Variable:                   14 Importance: 0.0006\n",
      "Variable:                   15 Importance: 0.0006\n",
      "Variable:                   17 Importance: 0.0006\n",
      "Variable:                   22 Importance: 0.0006\n",
      "Variable:                   23 Importance: 0.0006\n",
      "Variable:                   29 Importance: 0.0006\n",
      "Variable:                   32 Importance: 0.0006\n",
      "Variable:                   38 Importance: 0.0006\n",
      "Variable:                   59 Importance: 0.0006\n",
      "Variable:                   69 Importance: 0.0006\n",
      "Variable:                   78 Importance: 0.0006\n",
      "Variable:                   79 Importance: 0.0006\n",
      "Variable:                   85 Importance: 0.0006\n",
      "Variable:                   88 Importance: 0.0006\n",
      "Variable:                  101 Importance: 0.0006\n",
      "Variable: curr_team_1610612737 Importance: 0.0005\n",
      "Variable: curr_team_1610612750 Importance: 0.0005\n",
      "Variable: curr_team_1610612756 Importance: 0.0005\n",
      "Variable:                    0 Importance: 0.0005\n",
      "Variable:                    5 Importance: 0.0005\n",
      "Variable:                   11 Importance: 0.0005\n",
      "Variable:                   13 Importance: 0.0005\n",
      "Variable:                   18 Importance: 0.0005\n",
      "Variable:                   24 Importance: 0.0005\n",
      "Variable:                   26 Importance: 0.0005\n",
      "Variable:                   34 Importance: 0.0005\n",
      "Variable:                   39 Importance: 0.0005\n",
      "Variable:                   42 Importance: 0.0005\n",
      "Variable:                   43 Importance: 0.0005\n",
      "Variable:                   46 Importance: 0.0005\n",
      "Variable:                   49 Importance: 0.0005\n",
      "Variable:                   51 Importance: 0.0005\n",
      "Variable:                   65 Importance: 0.0005\n",
      "Variable:                   70 Importance: 0.0005\n",
      "Variable:                   71 Importance: 0.0005\n",
      "Variable:                   82 Importance: 0.0005\n",
      "Variable:                   84 Importance: 0.0005\n",
      "Variable:                   87 Importance: 0.0005\n",
      "Variable:                  112 Importance: 0.0005\n",
      "Variable:                  117 Importance: 0.0005\n",
      "Variable: curr_team_1610612751 Importance: 0.0004\n",
      "Variable: curr_team_1610612753 Importance: 0.0004\n",
      "Variable: curr_team_1610612759 Importance: 0.0004\n",
      "Variable: curr_team_1610612763 Importance: 0.0004\n",
      "Variable:                    1 Importance: 0.0004\n",
      "Variable:                    2 Importance: 0.0004\n",
      "Variable:                    7 Importance: 0.0004\n",
      "Variable:                    9 Importance: 0.0004\n",
      "Variable:                   16 Importance: 0.0004\n",
      "Variable:                   21 Importance: 0.0004\n",
      "Variable:                   35 Importance: 0.0004\n",
      "Variable:                   45 Importance: 0.0004\n",
      "Variable:                   50 Importance: 0.0004\n",
      "Variable:                   52 Importance: 0.0004\n",
      "Variable:                   61 Importance: 0.0004\n",
      "Variable:                   66 Importance: 0.0004\n",
      "Variable:                   74 Importance: 0.0004\n",
      "Variable: curr_team_1610612757 Importance: 0.0003\n",
      "Variable: curr_team_1610612758 Importance: 0.0003\n",
      "Variable: curr_team_1610612764 Importance: 0.0003\n",
      "Variable:                   36 Importance: 0.0003\n",
      "Variable:                   37 Importance: 0.0003\n",
      "Variable:                   40 Importance: 0.0003\n",
      "Variable:                   56 Importance: 0.0003\n",
      "Variable:                   60 Importance: 0.0003\n",
      "Variable:                   62 Importance: 0.0003\n",
      "Variable:                   89 Importance: 0.0003\n",
      "Variable:                  104 Importance: 0.0003\n",
      "Variable:                  111 Importance: 0.0003\n",
      "Variable:                  113 Importance: 0.0003\n",
      "Variable: curr_team_1610612760 Importance: 0.0002\n",
      "Variable:                   55 Importance: 0.0002\n",
      "Variable:                  110 Importance: 0.0002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "#scale the X variables\n",
    "X = large_df_of_sequences.loc[:, large_df_of_sequences.columns != 'Y']\n",
    "saved_columns = X.columns\n",
    "x = X.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "X = pd.DataFrame(x_scaled, columns=saved_columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Y = large_df_of_sequences['Y']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=10)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=1000, random_state=1)\n",
    "rf.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - y_test)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / y_test)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')\n",
    "    \n",
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 4)) for feature, importance in zip(X.columns, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];    \n",
    "\n",
    "y_predict = rf.predict(x_test)\n",
    "# print (\"R2 score:\",r2_score(y_test,y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  40 | elapsed:  6.5min remaining:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'bootstrap': False, 'max_depth': 150, 'max_features': 20, 'min_samples_leaf': 3, 'min_samples_split': 12, 'n_estimators': 500}\n",
      "Detailed classification report:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier , RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create param grid.\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [True,False],\n",
    "    'max_depth': [110,150],\n",
    "    'max_features': [20,200],\n",
    "    'min_samples_leaf': [3],\n",
    "    'min_samples_split': [ 12],\n",
    "    'n_estimators': [  500]\n",
    "}\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "best_clf = clf.fit(x_train, y_train)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(best_clf.best_params_)\n",
    "print(\"Detailed classification report:\")\n",
    "y_true, y_pred = y_test, best_clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6607073389f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# best_score, best_params = Grid_Search_CV_RFR(X_train, y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0my_test\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mbest_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Best Score:\"\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mbest_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_clf' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def RFR(X_train, X_test, y_train, y_test, best_params):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    estimator = RandomForestRegressor(n_jobs=-1).set_params(**best_params)\n",
    "    estimator.fit(X_train,y_train)\n",
    "    y_predict = estimator.predict(X_test)\n",
    "    print (\"R2 score:\",r2_score(y_test,y_predict))\n",
    "    return y_test,y_predict\n",
    "\n",
    "\n",
    "# best_score, best_params = Grid_Search_CV_RFR(X_train, y_train)\n",
    "y_test , y_predict = RFR(x_train, x_test, y_train, y_test ,best_clf.best_params_ )\n",
    "print (\"Best Score:\" ,best_clf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_game_score(\n",
    "                        curr_team_abv,\n",
    "                        opp_team,\n",
    "                        is_current_game_at_home,\n",
    "                        curr_team_id,\n",
    "                        df_g,\n",
    "                        df,\n",
    "                        pbp,\n",
    "                        shot_chart_df,\n",
    "                        col_order):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x = df_g[df_g['TEAM_ID'] == curr_team_id].sort_values('GAME_DATE').reset_index(drop=True)\n",
    "    tmp = x[-sliding_window_num_of_games:]\n",
    "\n",
    "    dummy_curr_team = pd.get_dummies(x['TEAM_ID'], prefix ='team').reindex(columns = dummy_nba_teams.columns, fill_value=0)\n",
    "    dummy_curr_team.columns = ['curr_' + col for col in dummy_curr_team.columns]\n",
    "    team_indicator = dummy_curr_team.loc[0].values\n",
    "\n",
    "    list_of_sequence_of_wins = list(tmp['IsWin'].values)\n",
    "    new_cols = []\n",
    "    for game in range(sliding_window_num_of_games):\n",
    "            new_cols.insert(0,'{}_games_back_IsWin'.format(game + 1))\n",
    "    df_of_sequence_of_wins = pd.DataFrame([list_of_sequence_of_wins],columns=new_cols)\n",
    "\n",
    "    # # get team indicator\n",
    "    team_indicator = dummy_curr_team[0:1]\n",
    "    team_indicator\n",
    "\n",
    "    # is at home\n",
    "    list_of_sequence_of_at_home = list(tmp['IsHome'].values)\n",
    "    new_cols = []\n",
    "    for game in range(sliding_window_num_of_games):\n",
    "            new_cols.insert(0,'{}_games_back_IsHome'.format(game + 1))\n",
    "    df_of_sequence_of_at_home = pd.DataFrame([list_of_sequence_of_at_home],columns=new_cols)\n",
    "    df_of_sequence_of_at_home['{}_games_back_IsHome'.format(sliding_window_num_of_games+1)] = is_current_game_at_home\n",
    "\n",
    "\n",
    "    # get opp team indicator \n",
    "\n",
    "    opp_dummy_teams = pd.get_dummies(tmp['Opposing_team_ID'].astype(int).append(pd.Series(opp_team_id)), prefix ='team').reindex(columns = dummy_nba_teams.columns, fill_value=0)\n",
    "    opp_dummy_teams.columns = ['opp_' + col for col in opp_dummy_teams.columns]\n",
    "    appended_list_of_encoded_opp_teams = list(itertools.chain(*opp_dummy_teams.values))\n",
    "    appended_df_of_encoded_opp_teams = pd.DataFrame([appended_list_of_encoded_opp_teams])\n",
    "\n",
    "    # add averages of categories\n",
    "    cols_to_calc = ['PTS','REB','AST','STL','BLK','TOV','PLUS_MINUS','FG3_PCT','FG_PCT','FT_PCT','num_of_possessions',\n",
    "                       'AdjustedPM','OffRating','EFG','AST_ratio','Opp_points','Def_Rating']\n",
    "    averages_of_categories_curr_team = tmp[cols_to_calc].mean().values\n",
    "    df_of_averages_of_categories_curr_team = pd.DataFrame([averages_of_categories_curr_team],columns=cols_to_calc)\n",
    "    df_of_averages_of_categories_curr_team\n",
    "\n",
    "    # add shot area avgs for curr team\n",
    "    shot_index= ['Mid-Range', 'In The Paint (Non-RA)', 'Restricted Area',\n",
    "    'Above the Break 3', 'Left Corner 3', 'Right Corner 3']\n",
    "\n",
    "    shot_chart_df_for_tmp = shot_chart_df[(shot_chart_df['GAME_ID'].isin(tmp['GAME_ID'].values))&\n",
    "                             (shot_chart_df['TEAM_ID']==curr_team_id)].groupby(\n",
    "                                ['SHOT_ZONE_BASIC']).mean()['SHOT_MADE_FLAG'].reset_index()\n",
    "    shot_chart_df_for_tmp_reindex = shot_chart_df_for_tmp[['SHOT_ZONE_BASIC','SHOT_MADE_FLAG']].set_index('SHOT_ZONE_BASIC').reindex(shot_index).fillna(0)\n",
    "    shot_area_avgs = shot_chart_df_for_tmp_reindex.T.reset_index(drop=True)\n",
    "    shot_area_avgs\n",
    "\n",
    "    # add shot chart of opposing teams during window\n",
    "    shot_chart_df_for_tmp = shot_chart_df[(shot_chart_df['GAME_ID'].isin(tmp[:-1]['GAME_ID'].values))&\n",
    "                             (shot_chart_df['TEAM_ID']!=curr_team_id)].groupby(\n",
    "                                ['SHOT_ZONE_BASIC']).mean()['SHOT_MADE_FLAG'].reset_index()\n",
    "    shot_chart_df_for_tmp_reindex = shot_chart_df_for_tmp[['SHOT_ZONE_BASIC','SHOT_MADE_FLAG']].set_index('SHOT_ZONE_BASIC').reindex(shot_index).fillna(0)\n",
    "    shot_area_avgs_opp = shot_chart_df_for_tmp_reindex.T.reset_index(drop=True)\n",
    "    shot_area_avgs_opp\n",
    "    \n",
    "    \n",
    "    # add sequence of scores\n",
    "    list_of_sequence_of_wins = list(tmp['PTS'].values)\n",
    "    new_cols = []\n",
    "    for game in range(sliding_window_num_of_games):\n",
    "            new_cols.insert(0,'{}_games_back_PTS'.format(game + 1))\n",
    "    df_of_sequence_of_scores = pd.DataFrame([list_of_sequence_of_wins],columns=new_cols)\n",
    "\n",
    "        \n",
    "     # add averages of categories\n",
    "    x_opp = df_g[df_g['TEAM_ID'] == opp_team_id].sort_values('GAME_DATE').reset_index(drop=True)\n",
    "    tmp_opp = x_opp[-sliding_window_num_of_games:]\n",
    "    cols_to_calc = ['PTS','REB','AST','STL','BLK','TOV','PLUS_MINUS','FG3_PCT','FG_PCT','FT_PCT','num_of_possessions',\n",
    "                       'AdjustedPM','OffRating','EFG','AST_ratio','Opp_points','Def_Rating']\n",
    "    averages_of_categories_opp_team = tmp_opp[cols_to_calc].mean().values\n",
    "    df_of_averages_of_categories_opp_team = pd.DataFrame([averages_of_categories_opp_team],columns=cols_to_calc)\n",
    "    df_of_averages_of_categories_opp_team\n",
    "    \n",
    "    # add sequence of pms\n",
    "    list_of_sequence_of_pm = list(tmp['PLUS_MINUS'].values)\n",
    "    new_cols = []\n",
    "    for game in range(sliding_window_num_of_games):\n",
    "            new_cols.insert(0,'{}_games_back_Plusminus'.format(game + 1))\n",
    "    df_of_sequence_of_plusminus = pd.DataFrame([list_of_sequence_of_pm],columns=new_cols)\n",
    "\n",
    "   # add sequence of days between games\n",
    "    tmp_days_back = x[-sliding_window_num_of_games-1:]\n",
    "    l = tmp_days_back['GAME_DATE'].diff().dt.days.dropna().values\n",
    "    l = [4 if sl >4 else sl for sl in l]\n",
    "    new_cols = []\n",
    "    for game in range(sliding_window_num_of_games):\n",
    "            new_cols.insert(0,'{}_games_back_PTS'.format(game + 1))\n",
    "    df_days_between = pd.DataFrame([l],columns=new_cols)\n",
    "\n",
    "\n",
    "    # start merging all together \n",
    "    # 1. wins\n",
    "    # 2. team indicator\n",
    "    # 3. at home indicator\n",
    "    # 4. TOV sequence\n",
    "    # print(len(team_indicator.columns),'team_indicator')\n",
    "    # print(len(df_of_sequence_of_wins.columns),'df_of_sequence_of_wins')\n",
    "    # print(len(df_of_sequence_of_at_home.columns),'df_of_sequence_of_at_home')\n",
    "    # print(len(appended_df_of_encoded_opp_teams.columns),'appended_df_of_encoded_opp_teams')\n",
    "    # print(len(df_of_averages_of_categories_curr_team.columns),'df_of_averages_of_categories_curr_team')\n",
    "    # print(len(shot_area_avgs.columns),'shot_area_avgs')\n",
    "    # print(len(shot_area_avgs_opp.columns),'shot_area_avgs_opp')\n",
    "    df_all_features = team_indicator.merge(df_of_sequence_of_wins , how='inner' , left_index=True , right_index=True)\n",
    "    df_all_features = df_all_features.merge(df_of_sequence_of_at_home, how='inner' , left_index=True , right_index=True)\n",
    "    df_all_features = df_all_features.merge(appended_df_of_encoded_opp_teams, how='inner' , left_index=True , right_index=True)\n",
    "    df_all_features = df_all_features.merge(df_of_averages_of_categories_curr_team, how='inner' , left_index=True , right_index=True)\n",
    "    df_all_features = df_all_features.merge(shot_area_avgs, how='inner' , left_index=True , right_index=True)\n",
    "    df_all_features = df_all_features.merge(shot_area_avgs_opp, how='inner' , left_index=True , right_index=True)\n",
    "    df_all_features = df_all_features.merge(df_of_sequence_of_scores, how='inner' , left_index=True , right_index=True)\n",
    "    df_all_features = df_all_features.merge(df_of_averages_of_categories_opp_team, how='inner' , left_index=True , right_index=True)\n",
    "    df_all_features = df_all_features.merge(df_of_sequence_of_plusminus, how='inner' , left_index=True , right_index=True)\n",
    "    df_all_features = df_all_features.merge(df_days_between, how='inner' , left_index=True , right_index=True)\n",
    "\n",
    "    len(df_all_features.columns)\n",
    "    df_all_features = df_all_features[col_order]\n",
    "#     df_all_features = df_all_features.loc[:, df_all_features.columns != 'Y']\n",
    "    df_all_features = pd.DataFrame(min_max_scaler.transform(df_all_features),columns=df_all_features.columns)\n",
    "    \n",
    "#     len(X.columns)\n",
    "\n",
    "    print([curr_team_abv,'------->' , best_clf.predict(df_all_features) , '-------',\n",
    "                        opp_team,\n",
    "                        is_current_game_at_home,\n",
    "                        curr_team_id])\n",
    "    print()\n",
    "    results_saved = [single_date,curr_team_abv, best_clf.predict(df_all_features)[0] ,\n",
    "                        opp_team,\n",
    "                        is_current_game_at_home,\n",
    "                        curr_team_id]\n",
    "    return results_saved\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "2020-01-06T00:00:00.000000000\n",
      "done\n",
      "['CHA', 'IND']\n",
      "['CHA', 'IND']\n",
      "2020-01-05 00:00:00\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'min_max_scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-b00c72c10f4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     76\u001b[0m                           \u001b[0mpbp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m                           \u001b[0mshot_chart_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m                             X.columns)\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[0mtotal_results_saved\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults_saved\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;31m#     predict_game_score(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-61-75877ae18db7>\u001b[0m in \u001b[0;36mpredict_game_score\u001b[1;34m(curr_team_abv, opp_team, is_current_game_at_home, curr_team_id, df_g, df, pbp, shot_chart_df, col_order)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[0mdf_all_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_all_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_order\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;31m#     df_all_features = df_all_features.loc[:, df_all_features.columns != 'Y']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m     \u001b[0mdf_all_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_max_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_all_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_all_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;31m#     len(X.columns)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'min_max_scaler' is not defined"
     ]
    }
   ],
   "source": [
    "# lsit_of_games = [\n",
    "#                 ['TOR','POR'] , \n",
    "#                 ['CLE','DET'] , \n",
    "#                 ['BKN','OKC'] , \n",
    "#                 ['MEM','MIN'] , \n",
    "#                 ['PHX','SAC'] , \n",
    "#                 ['LAL','NYK'] , \n",
    "                \n",
    "#             ]\n",
    "\n",
    "# df,df_g,pbp,shot_chart_df,team_abv_to_id_mapping = load_dfs( MAX_DATE = '2020-01-07')\n",
    "\n",
    "total_results_saved = []\n",
    "\n",
    "LAST_DATE_TO_RUN_ON = '2020-01-27'\n",
    "FIRST_DATE_TO_CHECK = '2020-01-01'\n",
    "\n",
    "\n",
    "df,df_g_global ,pbp,shot_chart_df,team_abv_to_id_mapping = load_dfs( MAX_DATE = LAST_DATE_TO_RUN_ON)\n",
    "\n",
    "list_of_games_to_check = df_g_global[['GAME_DATE','TEAM_ABBREVIATION','GAME_ID','IsHome']]\n",
    "len(list_of_games_to_check)\n",
    "merged_list_of_games_to_check = list_of_games_to_check.merge(list_of_games_to_check,\n",
    "                                                             how='inner',\n",
    "                                                             left_on =['GAME_ID'] ,\n",
    "                                                             right_on =['GAME_ID'])\n",
    "merged_list_of_games_to_check = merged_list_of_games_to_check[merged_list_of_games_to_check['TEAM_ABBREVIATION_x']!= merged_list_of_games_to_check['TEAM_ABBREVIATION_y']]\n",
    "merged_list_of_games_to_check=merged_list_of_games_to_check[merged_list_of_games_to_check['IsHome_x']==1]\n",
    "\n",
    "\n",
    "merged_list_of_games_to_check = merged_list_of_games_to_check[merged_list_of_games_to_check['GAME_DATE_x']>FIRST_DATE_TO_CHECK]\n",
    "list_of_dates = merged_list_of_games_to_check['GAME_DATE_x'].unique()\n",
    "for single_date in list_of_dates:\n",
    "    print (single_date)\n",
    "    lsit_of_games = []\n",
    "    for ix,row in merged_list_of_games_to_check[merged_list_of_games_to_check['GAME_DATE_x']==single_date].iterrows():\n",
    "        merged_list_of_games_to_check.iloc[1]\n",
    "        game=[row['TEAM_ABBREVIATION_x'],row['TEAM_ABBREVIATION_y']]\n",
    "        lsit_of_games.append(game)\n",
    "    df,df_g,pbp,shot_chart_df,team_abv_to_id_mapping = load_dfs( MAX_DATE = str(single_date)[:10])\n",
    "           \n",
    "        \n",
    "        \n",
    "        \n",
    "    sliding_window_num_of_games = 3\n",
    "\n",
    "    for game in lsit_of_games:\n",
    "        print(game)\n",
    "    #     print(df_g['GAME_DATE'].max())\n",
    "    #     df_g['TEAM_ABBREVIATION'].unique()\n",
    "        print(game)\n",
    "        print(df_g['GAME_DATE'].max())\n",
    "        df_g['TEAM_ABBREVIATION'].unique()\n",
    "        ###########################\n",
    "        ### DEFINE YOUR TEAMS   ###\n",
    "        ###########################\n",
    "        curr_team_abv = game[0] #'PHX'\n",
    "        curr_team_id = team_abv_to_id_mapping[curr_team_abv]\n",
    "\n",
    "        opp_team = game[1] #'SAC'\n",
    "        opp_team_id  = team_abv_to_id_mapping[opp_team]\n",
    "        is_current_game_at_home = 1\n",
    "\n",
    "\n",
    "\n",
    "        ###########################\n",
    "\n",
    "\n",
    "        results_saved = predict_game_score(\n",
    "                            curr_team_abv,\n",
    "                           opp_team,\n",
    "                           1,\n",
    "                           curr_team_id ,\n",
    "                          df_g,\n",
    "                          df,\n",
    "                          pbp,\n",
    "                          shot_chart_df,\n",
    "                            X.columns)\n",
    "        total_results_saved.append(results_saved)\n",
    "#     predict_game_score(\n",
    "#                         opp_team,\n",
    "#                        curr_team_abv,\n",
    "#                        0,\n",
    "#                        opp_team_id,\n",
    "#                       df_g,\n",
    "#                       df,\n",
    "#                       pbp,\n",
    "#                       shot_chart_df,\n",
    "#                     X.columns)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(total_results_saved, columns=['Date','HomeTeam', 'OutcomePM', 'AwayTeam' , 'IsHome' , 'HomeTeamID' ]).to_csv('~/pm_Jan.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "['DET', 'SAC']\n",
      "['DET', 'SAC']\n",
      "2020-01-21 00:00:00\n",
      "['DET', '------->', array([-0.19626291]), '-------', 'SAC', 1, 1610612765]\n",
      "\n",
      "['ORL', 'OKC']\n",
      "['ORL', 'OKC']\n",
      "2020-01-21 00:00:00\n",
      "['ORL', '------->', array([-4.22634606]), '-------', 'OKC', 1, 1610612753]\n",
      "\n",
      "['MIA', 'WAS']\n",
      "['MIA', 'WAS']\n",
      "2020-01-21 00:00:00\n",
      "['MIA', '------->', array([3.79342945]), '-------', 'WAS', 1, 1610612748]\n",
      "\n",
      "['NYK', 'LAL']\n",
      "['NYK', 'LAL']\n",
      "2020-01-21 00:00:00\n",
      "['NYK', '------->', array([-6.07346537]), '-------', 'LAL', 1, 1610612752]\n",
      "\n",
      "['TOR', 'PHI']\n",
      "['TOR', 'PHI']\n",
      "2020-01-21 00:00:00\n",
      "['TOR', '------->', array([2.64923547]), '-------', 'PHI', 1, 1610612761]\n",
      "\n",
      "['ATL', 'LAC']\n",
      "['ATL', 'LAC']\n",
      "2020-01-21 00:00:00\n",
      "['ATL', '------->', array([-1.81565051]), '-------', 'LAC', 1, 1610612737]\n",
      "\n",
      "['BOS', 'MEM']\n",
      "['BOS', 'MEM']\n",
      "2020-01-21 00:00:00\n",
      "['BOS', '------->', array([1.3496416]), '-------', 'MEM', 1, 1610612738]\n",
      "\n",
      "['NOP', 'SAS']\n",
      "['NOP', 'SAS']\n",
      "2020-01-21 00:00:00\n",
      "['NOP', '------->', array([-4.24866472]), '-------', 'SAS', 1, 1610612740]\n",
      "\n",
      "['HOU', 'DEN']\n",
      "['HOU', 'DEN']\n",
      "2020-01-21 00:00:00\n",
      "['HOU', '------->', array([-0.52729899]), '-------', 'DEN', 1, 1610612745]\n",
      "\n",
      "['CHI', 'MIN']\n",
      "['CHI', 'MIN']\n",
      "2020-01-21 00:00:00\n",
      "['CHI', '------->', array([-2.31737969]), '-------', 'MIN', 1, 1610612741]\n",
      "\n",
      "['PHX', 'IND']\n",
      "['PHX', 'IND']\n",
      "2020-01-21 00:00:00\n",
      "['PHX', '------->', array([2.26856986]), '-------', 'IND', 1, 1610612756]\n",
      "\n",
      "['GSW', 'UTA']\n",
      "['GSW', 'UTA']\n",
      "2020-01-21 00:00:00\n",
      "['GSW', '------->', array([-0.23873475]), '-------', 'UTA', 1, 1610612744]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# RUN PREDICTED\n",
    "################\n",
    "LAST_DATE_TO_RUN_ON = '2020-01-22'\n",
    "\n",
    "df,df_g_global ,pbp,shot_chart_df,team_abv_to_id_mapping = load_dfs( MAX_DATE = LAST_DATE_TO_RUN_ON)\n",
    "           \n",
    "lsit_of_games = [\n",
    "                ['DET','SAC'] , \n",
    "                ['ORL','OKC'] , \n",
    "                ['MIA','WAS'] , \n",
    "                ['NYK','LAL'] , \n",
    "                ['TOR','PHI'] , \n",
    "                ['ATL','LAC'] , \n",
    "                ['BOS','MEM'] , \n",
    "                ['NOP','SAS'] , \n",
    "                ['HOU','DEN'] , \n",
    "                ['CHI','MIN'] , \n",
    "                ['PHX','IND'] , \n",
    "                ['GSW','UTA'] , \n",
    "    \n",
    "                \n",
    "            ]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "sliding_window_num_of_games = 4\n",
    "\n",
    "for game in lsit_of_games:\n",
    "    print(game)\n",
    "#     print(df_g['GAME_DATE'].max())\n",
    "#     df_g['TEAM_ABBREVIATION'].unique()\n",
    "    print(game)\n",
    "    print(df_g_global['GAME_DATE'].max())\n",
    "    df_g['TEAM_ABBREVIATION'].unique()\n",
    "    ###########################\n",
    "    ### DEFINE YOUR TEAMS   ###\n",
    "    ###########################\n",
    "    curr_team_abv = game[0] #'PHX'\n",
    "    curr_team_id = team_abv_to_id_mapping[curr_team_abv]\n",
    "\n",
    "    opp_team = game[1] #'SAC'\n",
    "    opp_team_id  = team_abv_to_id_mapping[opp_team]\n",
    "    is_current_game_at_home = 1\n",
    "\n",
    "\n",
    "\n",
    "    ###########################\n",
    "\n",
    "\n",
    "    predict_game_score(\n",
    "                        curr_team_abv,\n",
    "                       opp_team,\n",
    "                       1,\n",
    "                       curr_team_id ,\n",
    "                      df_g_global,\n",
    "                      df,\n",
    "                      pbp,\n",
    "                      shot_chart_df,\n",
    "                        X.columns)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
