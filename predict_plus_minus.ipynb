{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current State - \n",
    "# 5 days \n",
    "# MAX_DATE = '2020-01-01'\n",
    "# MIN_DATE = '2018-11-01'\n",
    "# With normalization\n",
    "\n",
    "# PM 0.6826923076923077\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_possessions_per_game_and_team(row,pbp):\n",
    "    try:\n",
    "        GAME_ID = row['GAME_ID']\n",
    "        is_home = row['IsHome']\n",
    "        single_game = pbp[pbp['GAME_ID']==GAME_ID]\n",
    "        index_indicator = 'Home_EOP' if is_home==1 else 'Visitor_EOP'\n",
    "\n",
    "        single_game = single_game.sort_values('EVENTNUM')\n",
    "        single_game['Shift_HOMEDESCRIPTION'] = single_game['HOMEDESCRIPTION'].shift(-1)\n",
    "        single_game[['Shift_HOMEDESCRIPTION','HOMEDESCRIPTION']]\n",
    "        single_game.loc[(single_game['HOMEDESCRIPTION'].isnull()==False)&\n",
    "                        (single_game['Shift_HOMEDESCRIPTION'].isnull()==True)&\n",
    "                        (single_game['EVENTMSGTYPE'].isin([1,2,3,4,5,7,9])),'Home_EOP'] = 1\n",
    "        single_game['Home_EOP'].fillna(0,inplace=True)\n",
    "        single_game[['Shift_HOMEDESCRIPTION','HOMEDESCRIPTION','VISITORDESCRIPTION','Home_EOP']]\n",
    "\n",
    "        single_game['Shift_VISITORDESCRIPTION'] = single_game['VISITORDESCRIPTION'].shift(-1)\n",
    "        single_game[['Shift_VISITORDESCRIPTION','VISITORDESCRIPTION']]\n",
    "        single_game.loc[(single_game['VISITORDESCRIPTION'].isnull()==False)&\n",
    "                        (single_game['Shift_VISITORDESCRIPTION'].isnull()==True)&\n",
    "                        (single_game['EVENTMSGTYPE'].isin([1,2,3,4,5,7,9])),'Visitor_EOP'] = 1\n",
    "        single_game['Visitor_EOP'].fillna(0,inplace=True)\n",
    "        return single_game[['Home_EOP','Visitor_EOP']].sum().loc[index_indicator]\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "def load_dfs( MAX_DATE = None , MIN_DATE = None):\n",
    "    nba_teams = ['MIL', 'CHI', 'CHA', 'TOR', 'BOS', 'PHX', 'OKC', 'LAC', 'IND',\n",
    "           'BKN', 'MIN', 'UTA', 'SAS', 'DAL', 'CLE', 'NYK', 'POR', 'HOU',\n",
    "           'DEN', 'MEM', 'SAC', 'PHI',  'ATL', 'LAL', \n",
    "           'WAS', 'ORL', 'GSW', 'NOP', \n",
    "           'MIA', \n",
    "           'DET']\n",
    "    nba_team_ids =[1610612749, 1610612766, 1610612738, 1610612746, 1610612754,\n",
    "           1610612750, 1610612741, 1610612742, 1610612762, 1610612759,\n",
    "           1610612739, 1610612752, 1610612761, 1610612760, 1610612757,\n",
    "           1610612751, 1610612745, 1610612756, 1610612743, 1610612755,\n",
    "           1610612737, 1610612763, 1610612764, 1610612744, 1610612740,\n",
    "           1610612753, 1610612747, 1610612758, 1610612748, 1610612765]\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "    nba_teams_df = pd.DataFrame(nba_teams)\n",
    "    dummy_nba_teams= pd.get_dummies(nba_team_ids, prefix ='team')\n",
    "\n",
    "\n",
    "    df = pd.read_csv('large_boxscoretraditionalv2_df.csv')\n",
    "    df=df[df['TEAM_ID'].isin(nba_team_ids)]\n",
    "    df.drop_duplicates(subset = ['GAME_ID','PLAYER_ID'],inplace=True)\n",
    "    df.dropna(subset=['MIN'],inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    df_g = pd.read_csv('all_games.csv')\n",
    "    df_g.drop_duplicates(subset =['TEAM_ID','GAME_ID'],inplace=True)\n",
    "\n",
    "    df_g.loc[df_g['WL']=='W','IsWin']=1\n",
    "    df_g.loc[df_g['WL']=='L','IsWin']=0\n",
    "    df_g['IsHome'] = (df_g['MATCHUP'].str.contains('vs.')).astype(int)\n",
    "    df_g['Opposing_team'] = df_g['MATCHUP'].apply( lambda x: x.split(' ')[2])\n",
    "\n",
    "    df_g=df_g[df_g['TEAM_ID'].isin(nba_team_ids)]\n",
    "    team_abv_to_id_mapping = df_g[['TEAM_ABBREVIATION','TEAM_ID']].drop_duplicates().set_index('TEAM_ABBREVIATION')['TEAM_ID'].to_dict()\n",
    "    df_g['Opposing_team_ID'] = df_g['Opposing_team'].apply(lambda x: team_abv_to_id_mapping[x] if x in team_abv_to_id_mapping else None )\n",
    "\n",
    "    df_g=df_g[df_g['Opposing_team_ID'].isin(nba_team_ids)]\n",
    "\n",
    "    # df_g=df_g[['GAME_ID','TEAM_ID','GAME_DATE']].drop_duplicates().dropna()\n",
    "    df_g['GAME_DATE'] = pd.to_datetime(df_g['GAME_DATE'])\n",
    "    \n",
    "    if MAX_DATE is not None:\n",
    "        df_g = df_g[df_g['GAME_DATE']<MAX_DATE]\n",
    "    if MIN_DATE is not None:\n",
    "        df_g = df_g[df_g['GAME_DATE']>MIN_DATE]\n",
    "    # add balance scoring\n",
    "\n",
    "\n",
    "    df = df.merge(df_g, \n",
    "         how='inner',\n",
    "         left_on=['GAME_ID','TEAM_ID'],\n",
    "         right_on=['GAME_ID','TEAM_ID'])\n",
    "\n",
    "\n",
    "    pbp = pd.read_csv('large_playbyplayv2_df.csv', index_col=0)\n",
    "    pbp.drop_duplicates(subset=['GAME_ID','EVENTNUM','PERIOD'], inplace=True)\n",
    "\n",
    "\n",
    "    shot_chart_df =  pd.read_csv('ShotChartDetail_v2.csv')\n",
    "    shot_chart_df.drop_duplicates(subset=['GAME_ID','GAME_EVENT_ID'], inplace=True)\n",
    "    \n",
    "    \n",
    "    df_g['num_of_possessions'] = df_g.apply( lambda x: get_possessions_per_game_and_team(x,pbp), axis=1)\n",
    "    df_g.dropna(subset=['num_of_possessions'],inplace=True)\n",
    "    df_g['AdjustedPM'] = (df_g['PLUS_MINUS']/df_g['num_of_possessions'])*100\n",
    "    df_g['OffRating'] = (df_g['PTS']/df_g['num_of_possessions'])*100\n",
    "    df_g['EFG'] = (df_g['FGM'] + 0.5*df_g['FG3M'])/df_g['FGA']\n",
    "    df_g['AST_ratio'] = df_g['AST']*100/((df_g['FGA'])+(df_g['FTA']*0.44)+(df_g['AST'])+(df_g['AST']))\n",
    "    df_g['Opp_points'] = df_g['PTS'] + df_g['PLUS_MINUS']\n",
    "    df_g['Def_Rating'] = (df_g['Opp_points'] / df_g['num_of_possessions'])*100\n",
    "\n",
    "    ['AdjustedPM','OffRating','EFG','AST_ratio','Opp_points','Def_Rating']\n",
    "\n",
    "    print('done')\n",
    "    return df,df_g,pbp,shot_chart_df,team_abv_to_id_mapping\n",
    "\n",
    "df,df_g,pbp,shot_chart_df,team_abv_to_id_mapping = load_dfs(  MAX_DATE = '2020-02-10',MIN_DATE = '2018-10-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1610612749\n",
      "1610612766\n",
      "1610612738\n",
      "1610612746\n",
      "1610612754\n",
      "1610612750\n",
      "1610612741\n",
      "1610612742\n",
      "1610612762\n",
      "1610612759\n",
      "1610612739\n",
      "1610612752\n",
      "1610612761\n",
      "1610612760\n",
      "1610612757\n",
      "1610612751\n",
      "1610612745\n",
      "1610612756\n",
      "1610612743\n",
      "1610612755\n",
      "1610612737\n",
      "1610612763\n",
      "1610612764\n",
      "1610612744\n",
      "1610612740\n",
      "1610612753\n",
      "1610612747\n",
      "1610612758\n",
      "1610612748\n",
      "1610612765\n"
     ]
    }
   ],
   "source": [
    "nba_teams = ['MIL', 'CHI', 'CHA', 'TOR', 'BOS', 'PHX', 'OKC', 'LAC', 'IND',\n",
    "       'BKN', 'MIN', 'UTA', 'SAS', 'DAL', 'CLE', 'NYK', 'POR', 'HOU',\n",
    "       'DEN', 'MEM', 'SAC', 'PHI',  'ATL', 'LAL', \n",
    "       'WAS', 'ORL', 'GSW', 'NOP', \n",
    "       'MIA', \n",
    "       'DET']\n",
    "nba_team_ids =[1610612749, 1610612766, 1610612738, 1610612746, 1610612754,\n",
    "       1610612750, 1610612741, 1610612742, 1610612762, 1610612759,\n",
    "       1610612739, 1610612752, 1610612761, 1610612760, 1610612757,\n",
    "       1610612751, 1610612745, 1610612756, 1610612743, 1610612755,\n",
    "       1610612737, 1610612763, 1610612764, 1610612744, 1610612740,\n",
    "       1610612753, 1610612747, 1610612758, 1610612748, 1610612765]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nba_teams_df = pd.DataFrame(nba_teams)\n",
    "dummy_nba_teams= pd.get_dummies(nba_team_ids, prefix ='team')\n",
    "\n",
    "sliding_window_num_of_games = 5\n",
    "\n",
    "large_df_of_sequences = pd.DataFrame([])\n",
    " \n",
    "# create the sliding window dataframe per team\n",
    "for team in nba_team_ids:\n",
    "    print(team)\n",
    "    x = df_g[df_g['TEAM_ID'] == team].sort_values('GAME_DATE').reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    dummy_curr_team = pd.get_dummies(x['TEAM_ID'], prefix ='team').reindex(columns = dummy_nba_teams.columns, fill_value=0)\n",
    "    dummy_curr_team.columns = ['curr_' + col for col in dummy_curr_team.columns]\n",
    "    team_indicator = dummy_curr_team.loc[0].values\n",
    "    \n",
    "    \n",
    "    list_team_indicator = list(team_indicator) \n",
    "    for ix,row in x[sliding_window_num_of_games:].iterrows():\n",
    "        tmp = x.loc[ix-sliding_window_num_of_games:ix]\n",
    "        \n",
    "        # add sequence of wins\n",
    "        list_of_sequence_of_wins = list(tmp['IsWin'].values[:-1])\n",
    "        new_cols = []\n",
    "        for game in range(sliding_window_num_of_games):\n",
    "                new_cols.insert(0,'{}_games_back_IsWin'.format(game + 1))\n",
    "        df_of_sequence_of_wins = pd.DataFrame([list_of_sequence_of_wins],columns=new_cols)\n",
    "        \n",
    "        # get team indicator\n",
    "        team_indicator = dummy_curr_team[0:1]\n",
    "        \n",
    "        # is at home\n",
    "        list_of_sequence_of_at_home = list(tmp['IsHome'].values)\n",
    "        new_cols = []\n",
    "        for game in range(sliding_window_num_of_games+1):\n",
    "                new_cols.insert(0,'{}_games_back_IsHome'.format(game + 1))\n",
    "        df_of_sequence_of_at_home = pd.DataFrame([list_of_sequence_of_at_home],columns=new_cols)\n",
    "        \n",
    "        # get opp team indicator \n",
    "        opp_dummy_teams = pd.get_dummies(tmp['Opposing_team_ID'].astype(int), prefix ='team').reindex(columns = dummy_nba_teams.columns, fill_value=0)\n",
    "        opp_dummy_teams.columns = ['opp_' + col for col in opp_dummy_teams.columns]\n",
    "        appended_list_of_encoded_opp_teams = list(itertools.chain(*opp_dummy_teams.values))\n",
    "        appended_df_of_encoded_opp_teams = pd.DataFrame([appended_list_of_encoded_opp_teams])\n",
    "        \n",
    "        \n",
    "        # add averages of categories\n",
    "        cols_to_calc = ['PTS','REB','AST','STL','BLK','TOV','PLUS_MINUS','FG3_PCT','FG_PCT','FT_PCT','num_of_possessions',\n",
    "                       'AdjustedPM','OffRating','EFG','AST_ratio','Opp_points','Def_Rating'\n",
    "                       ]\n",
    "        averages_of_categories_curr_team = tmp[cols_to_calc][:-1].mean().values\n",
    "        df_of_averages_of_categories_curr_team = pd.DataFrame([averages_of_categories_curr_team],columns =cols_to_calc)\n",
    "        \n",
    "        \n",
    "        # add shot area avgs for curr team\n",
    "        shot_index= ['Mid-Range', 'In The Paint (Non-RA)', 'Restricted Area',\n",
    "       'Above the Break 3', 'Left Corner 3', 'Right Corner 3']\n",
    "\n",
    "        shot_chart_df_for_tmp = shot_chart_df[(shot_chart_df['GAME_ID'].isin(tmp[:-1]['GAME_ID'].values))&\n",
    "                                 (shot_chart_df['TEAM_ID']==team)].groupby(\n",
    "                                    ['SHOT_ZONE_BASIC']).mean()['SHOT_MADE_FLAG'].reset_index()\n",
    "        shot_chart_df_for_tmp_reindex = shot_chart_df_for_tmp[['SHOT_ZONE_BASIC','SHOT_MADE_FLAG']].set_index('SHOT_ZONE_BASIC').reindex(shot_index).fillna(0)\n",
    "        shot_area_avgs = shot_chart_df_for_tmp_reindex.T.reset_index(drop=True)\n",
    "        \n",
    "        # add shot chart of opposing teams during window\n",
    "        shot_chart_df_for_tmp = shot_chart_df[(shot_chart_df['GAME_ID'].isin(tmp[:-1]['GAME_ID'].values))&\n",
    "                                 (shot_chart_df['TEAM_ID']!=team)].groupby(\n",
    "                                    ['SHOT_ZONE_BASIC']).mean()['SHOT_MADE_FLAG'].reset_index()\n",
    "        shot_chart_df_for_tmp_reindex = shot_chart_df_for_tmp[['SHOT_ZONE_BASIC','SHOT_MADE_FLAG']].set_index('SHOT_ZONE_BASIC').reindex(shot_index).fillna(0)\n",
    "        shot_area_avgs_opp = shot_chart_df_for_tmp_reindex.T.reset_index(drop=True)\n",
    "        \n",
    "        # add sequence of scores\n",
    "        list_of_sequence_of_wins = list(tmp['PTS'].values[:-1])\n",
    "        new_cols = []\n",
    "        for game in range(sliding_window_num_of_games):\n",
    "                new_cols.insert(0,'{}_games_back_PTS'.format(game + 1))\n",
    "        \n",
    "        df_of_sequence_of_scores = pd.DataFrame([list_of_sequence_of_wins],columns=new_cols)\n",
    "        \n",
    "        \n",
    "         # add averages of categories for past opponents\n",
    "        list_of_opp_ids = list(tmp['Opposing_team_ID'].unique())\n",
    "\n",
    "        x_opp = df_g[(df_g['TEAM_ID'].isin(list_of_opp_ids))&\n",
    "                    (df_g['GAME_DATE'] < tmp['GAME_DATE'].max())&\n",
    "                    (df_g['GAME_DATE'] >= tmp['GAME_DATE'].min())].sort_values('GAME_DATE').reset_index(drop=True)\n",
    "        tmp_opp = x_opp[-sliding_window_num_of_games:ix]\n",
    "        cols_to_calc = ['PTS','REB','AST','STL','BLK','TOV','PLUS_MINUS','FG3_PCT','FG_PCT','FT_PCT','num_of_possessions',\n",
    "                       'AdjustedPM','OffRating','EFG','AST_ratio','Opp_points','Def_Rating']\n",
    "        averages_of_categories_opp_team = tmp_opp[cols_to_calc].mean().values\n",
    "        df_of_averages_of_categories_opp_team = pd.DataFrame([averages_of_categories_opp_team],columns = cols_to_calc).reset_index(drop=True)\n",
    "        \n",
    "        # add sequence of pms\n",
    "        list_of_sequence_of_pm = list(tmp['PLUS_MINUS'].values)\n",
    "        new_cols = []\n",
    "        for game in range(sliding_window_num_of_games):\n",
    "                new_cols.insert(0,'{}_games_back_Plusminus'.format(game + 1))\n",
    "        new_cols.append('Y') \n",
    "        df_of_sequence_of_plusminus = pd.DataFrame([list_of_sequence_of_pm],columns=new_cols)\n",
    "        \n",
    "        \n",
    "        # add sequence of days between games\n",
    "        tmp['GAME_DATE'].diff().dt.days.dropna()\n",
    "        l = tmp['GAME_DATE'].diff().dt.days.dropna().values\n",
    "        l = [4 if sl >4 else sl for sl in l]\n",
    "        new_cols = []\n",
    "        for game in range(sliding_window_num_of_games):\n",
    "                new_cols.insert(0,'{}_games_back_PTS'.format(game + 1))\n",
    "\n",
    "        df_days_between = pd.DataFrame([l],columns=new_cols)\n",
    "\n",
    "        # start merging all together \n",
    "        # 1. wins\n",
    "        # 2. team indicator\n",
    "        # 3. at home indicator\n",
    "        # 4. TOV sequence\n",
    "#         print(len(team_indicator.columns),'team_indicator')\n",
    "#         print(len(df_of_sequence_of_wins.columns),'df_of_sequence_of_wins')\n",
    "#         print(len(df_of_sequence_of_at_home.columns),'df_of_sequence_of_at_home')\n",
    "#         print(len(appended_df_of_encoded_opp_teams.columns),'appended_df_of_encoded_opp_teams')\n",
    "#         print(len(df_of_averages_of_categories_curr_team.columns),'df_of_averages_of_categories_curr_team')\n",
    "#         print(len(shot_area_avgs.columns),'shot_area_avgs')\n",
    "#         print(len(shot_area_avgs_opp.columns),'shot_area_avgs_opp')\n",
    "        \n",
    "        df_all_features = team_indicator.merge(df_of_sequence_of_wins , how='inner' , left_index=True , right_index=True)\n",
    "        df_all_features = df_all_features.merge(df_of_sequence_of_at_home, how='inner' , left_index=True , right_index=True)\n",
    "        df_all_features = df_all_features.merge(appended_df_of_encoded_opp_teams, how='inner' , left_index=True , right_index=True)\n",
    "        df_all_features = df_all_features.merge(df_of_averages_of_categories_curr_team, how='inner' , left_index=True , right_index=True)\n",
    "        df_all_features = df_all_features.merge(shot_area_avgs, how='inner' , left_index=True , right_index=True)\n",
    "        df_all_features = df_all_features.merge(shot_area_avgs_opp, how='inner' , left_index=True , right_index=True)\n",
    "        df_all_features = df_all_features.merge(df_of_sequence_of_scores, how='inner' , left_index=True , right_index=True)\n",
    "        df_all_features = df_all_features.merge(df_of_averages_of_categories_opp_team, how='inner' , left_index=True , right_index=True)\n",
    "        df_all_features = df_all_features.merge(df_of_sequence_of_plusminus, how='inner' , left_index=True , right_index=True)\n",
    "        df_all_features = df_all_features.merge(df_days_between, how='inner' , left_index=True , right_index=True)\n",
    "\n",
    "        large_df_of_sequences = large_df_of_sequences.append(df_all_features)\n",
    "    \n",
    "large_df_of_sequences.dropna(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 10.26 degrees.\n",
      "Accuracy: 97.16 %.\n",
      "Variable: AdjustedPM_x         Importance: 0.0498\n",
      "Variable: 1_games_back_IsHome  Importance: 0.0277\n",
      "Variable: FT_PCT_x             Importance: 0.0197\n",
      "Variable: Above the Break 3_y  Importance: 0.0186\n",
      "Variable: FT_PCT_y             Importance: 0.0184\n",
      "Variable: In The Paint (Non-RA)_y Importance: 0.0183\n",
      "Variable: FG3_PCT_y            Importance: 0.0181\n",
      "Variable: Above the Break 3_x  Importance: 0.0176\n",
      "Variable: PLUS_MINUS_x         Importance: 0.0174\n",
      "Variable: 4_games_back_Plusminus Importance: 0.0173\n",
      "Variable: BLK_x                Importance: 0.0169\n",
      "Variable: Mid-Range_x          Importance: 0.0166\n",
      "Variable: Restricted Area_y    Importance: 0.0158\n",
      "Variable: 1_games_back_PTS_x   Importance: 0.0152\n",
      "Variable: Restricted Area_x    Importance: 0.0149\n",
      "Variable: num_of_possessions_y Importance: 0.0149\n",
      "Variable: FG3_PCT_x            Importance: 0.0148\n",
      "Variable: 5_games_back_Plusminus Importance: 0.0143\n",
      "Variable: In The Paint (Non-RA)_x Importance: 0.0139\n",
      "Variable: BLK_y                Importance: 0.0138\n",
      "Variable: TOV_y                Importance: 0.0137\n",
      "Variable: Right Corner 3_y     Importance: 0.0136\n",
      "Variable: REB_y                Importance: 0.0136\n",
      "Variable: 2_games_back_Plusminus Importance: 0.0135\n",
      "Variable: TOV_x                Importance: 0.0134\n",
      "Variable: REB_x                Importance: 0.0133\n",
      "Variable: num_of_possessions_x Importance: 0.0132\n",
      "Variable: AST_ratio_x          Importance: 0.0132\n",
      "Variable: Mid-Range_y          Importance: 0.0132\n",
      "Variable: 3_games_back_Plusminus Importance: 0.013\n",
      "Variable: Left Corner 3_y      Importance: 0.0128\n",
      "Variable: Right Corner 3_x     Importance: 0.0127\n",
      "Variable: Left Corner 3_x      Importance: 0.0126\n",
      "Variable: 4_games_back_PTS_x   Importance: 0.0126\n",
      "Variable: 1_games_back_Plusminus Importance: 0.0125\n",
      "Variable: Def_Rating_x         Importance: 0.0124\n",
      "Variable: PTS_y                Importance: 0.0124\n",
      "Variable: OffRating_y          Importance: 0.0124\n",
      "Variable: STL_y                Importance: 0.0123\n",
      "Variable: 5_games_back_PTS_x   Importance: 0.0121\n",
      "Variable: 2_games_back_PTS_x   Importance: 0.0121\n",
      "Variable: 3_games_back_PTS_x   Importance: 0.012\n",
      "Variable: AST_ratio_y          Importance: 0.0118\n",
      "Variable: FG_PCT_x             Importance: 0.0116\n",
      "Variable: FG_PCT_y             Importance: 0.0115\n",
      "Variable: STL_x                Importance: 0.0113\n",
      "Variable: OffRating_x          Importance: 0.0113\n",
      "Variable: EFG_x                Importance: 0.0112\n",
      "Variable: Opp_points_x         Importance: 0.011\n",
      "Variable: AST_x                Importance: 0.0107\n",
      "Variable: Opp_points_y         Importance: 0.0102\n",
      "Variable: EFG_y                Importance: 0.0101\n",
      "Variable: AdjustedPM_y         Importance: 0.01\n",
      "Variable: AST_y                Importance: 0.0097\n",
      "Variable:                  162 Importance: 0.0096\n",
      "Variable: PTS_x                Importance: 0.0096\n",
      "Variable: Def_Rating_y         Importance: 0.0091\n",
      "Variable:                  152 Importance: 0.0087\n",
      "Variable:                  165 Importance: 0.0086\n",
      "Variable: PLUS_MINUS_y         Importance: 0.0079\n",
      "Variable: curr_team_1610612749 Importance: 0.0055\n",
      "Variable: 1_games_back_PTS_y   Importance: 0.0036\n",
      "Variable: 3_games_back_PTS_y   Importance: 0.0033\n",
      "Variable: 2_games_back_PTS_y   Importance: 0.0033\n",
      "Variable: 5_games_back_PTS_y   Importance: 0.0029\n",
      "Variable:                  168 Importance: 0.0028\n",
      "Variable:                  150 Importance: 0.0027\n",
      "Variable:                  154 Importance: 0.0027\n",
      "Variable:                  175 Importance: 0.0025\n",
      "Variable:                  174 Importance: 0.0023\n",
      "Variable: 4_games_back_PTS_y   Importance: 0.0023\n",
      "Variable: curr_team_1610612737 Importance: 0.002\n",
      "Variable: curr_team_1610612741 Importance: 0.002\n",
      "Variable: curr_team_1610612739 Importance: 0.0019\n",
      "Variable: 2_games_back_IsHome  Importance: 0.0019\n",
      "Variable: 6_games_back_IsHome  Importance: 0.0018\n",
      "Variable: 5_games_back_IsHome  Importance: 0.0017\n",
      "Variable: 3_games_back_IsHome  Importance: 0.0017\n",
      "Variable: curr_team_1610612766 Importance: 0.0016\n",
      "Variable: 4_games_back_IsHome  Importance: 0.0016\n",
      "Variable:                  169 Importance: 0.0016\n",
      "Variable:                   14 Importance: 0.0015\n",
      "Variable: curr_team_1610612752 Importance: 0.0014\n",
      "Variable:                  151 Importance: 0.0014\n",
      "Variable:                  158 Importance: 0.0014\n",
      "Variable:                   20 Importance: 0.0013\n",
      "Variable:                  166 Importance: 0.0013\n",
      "Variable:                    2 Importance: 0.0012\n",
      "Variable:                   70 Importance: 0.0011\n",
      "Variable:                   87 Importance: 0.0011\n",
      "Variable:                  179 Importance: 0.0011\n",
      "Variable: curr_team_1610612743 Importance: 0.001\n",
      "Variable: curr_team_1610612754 Importance: 0.001\n",
      "Variable:                   58 Importance: 0.001\n",
      "Variable:                   84 Importance: 0.001\n",
      "Variable:                  135 Importance: 0.001\n",
      "Variable:                  167 Importance: 0.001\n",
      "Variable: curr_team_1610612745 Importance: 0.0009\n",
      "Variable:                   24 Importance: 0.0009\n",
      "Variable:                   25 Importance: 0.0009\n",
      "Variable:                   49 Importance: 0.0009\n",
      "Variable:                   85 Importance: 0.0009\n",
      "Variable:                  125 Importance: 0.0009\n",
      "Variable: curr_team_1610612747 Importance: 0.0008\n",
      "Variable: curr_team_1610612755 Importance: 0.0008\n",
      "Variable:                    1 Importance: 0.0008\n",
      "Variable:                   13 Importance: 0.0008\n",
      "Variable:                   28 Importance: 0.0008\n",
      "Variable:                   46 Importance: 0.0008\n",
      "Variable:                   90 Importance: 0.0008\n",
      "Variable:                   91 Importance: 0.0008\n",
      "Variable:                  114 Importance: 0.0008\n",
      "Variable:                  137 Importance: 0.0008\n",
      "Variable:                  140 Importance: 0.0008\n",
      "Variable:                  155 Importance: 0.0008\n",
      "Variable:                  157 Importance: 0.0008\n",
      "Variable: curr_team_1610612753 Importance: 0.0007\n",
      "Variable: curr_team_1610612756 Importance: 0.0007\n",
      "Variable: 5_games_back_IsWin   Importance: 0.0007\n",
      "Variable: 3_games_back_IsWin   Importance: 0.0007\n",
      "Variable: 1_games_back_IsWin   Importance: 0.0007\n",
      "Variable:                    8 Importance: 0.0007\n",
      "Variable:                   18 Importance: 0.0007\n",
      "Variable:                   27 Importance: 0.0007\n",
      "Variable:                   35 Importance: 0.0007\n",
      "Variable:                   45 Importance: 0.0007\n",
      "Variable:                   47 Importance: 0.0007\n",
      "Variable:                   52 Importance: 0.0007\n",
      "Variable:                   53 Importance: 0.0007\n",
      "Variable:                   77 Importance: 0.0007\n",
      "Variable:                  107 Importance: 0.0007\n",
      "Variable:                  112 Importance: 0.0007\n",
      "Variable:                  117 Importance: 0.0007\n",
      "Variable:                  119 Importance: 0.0007\n",
      "Variable:                  121 Importance: 0.0007\n",
      "Variable:                  128 Importance: 0.0007\n",
      "Variable:                  129 Importance: 0.0007\n",
      "Variable:                  177 Importance: 0.0007\n",
      "Variable:                  178 Importance: 0.0007\n",
      "Variable: curr_team_1610612744 Importance: 0.0006\n",
      "Variable: curr_team_1610612761 Importance: 0.0006\n",
      "Variable: 4_games_back_IsWin   Importance: 0.0006\n",
      "Variable: 2_games_back_IsWin   Importance: 0.0006\n",
      "Variable:                   32 Importance: 0.0006\n",
      "Variable:                   43 Importance: 0.0006\n",
      "Variable:                   60 Importance: 0.0006\n",
      "Variable:                   68 Importance: 0.0006\n",
      "Variable:                   69 Importance: 0.0006\n",
      "Variable:                   71 Importance: 0.0006\n",
      "Variable:                   75 Importance: 0.0006\n",
      "Variable:                  104 Importance: 0.0006\n",
      "Variable:                  115 Importance: 0.0006\n",
      "Variable:                  124 Importance: 0.0006\n",
      "Variable:                  131 Importance: 0.0006\n",
      "Variable:                  146 Importance: 0.0006\n",
      "Variable:                  147 Importance: 0.0006\n",
      "Variable: curr_team_1610612742 Importance: 0.0005\n",
      "Variable: curr_team_1610612746 Importance: 0.0005\n",
      "Variable: curr_team_1610612748 Importance: 0.0005\n",
      "Variable: curr_team_1610612750 Importance: 0.0005\n",
      "Variable:                    4 Importance: 0.0005\n",
      "Variable:                   12 Importance: 0.0005\n",
      "Variable:                   15 Importance: 0.0005\n",
      "Variable:                   22 Importance: 0.0005\n",
      "Variable:                   31 Importance: 0.0005\n",
      "Variable:                   33 Importance: 0.0005\n",
      "Variable:                   41 Importance: 0.0005\n",
      "Variable:                   44 Importance: 0.0005\n",
      "Variable:                   51 Importance: 0.0005\n",
      "Variable:                   54 Importance: 0.0005\n",
      "Variable:                   56 Importance: 0.0005\n",
      "Variable:                   57 Importance: 0.0005\n",
      "Variable:                   64 Importance: 0.0005\n",
      "Variable:                   66 Importance: 0.0005\n",
      "Variable:                   73 Importance: 0.0005\n",
      "Variable:                   74 Importance: 0.0005\n",
      "Variable:                   76 Importance: 0.0005\n",
      "Variable:                   79 Importance: 0.0005\n",
      "Variable:                   80 Importance: 0.0005\n",
      "Variable:                   89 Importance: 0.0005\n",
      "Variable:                   93 Importance: 0.0005\n",
      "Variable:                  100 Importance: 0.0005\n",
      "Variable:                  101 Importance: 0.0005\n",
      "Variable:                  108 Importance: 0.0005\n",
      "Variable:                  110 Importance: 0.0005\n",
      "Variable:                  111 Importance: 0.0005\n",
      "Variable:                  118 Importance: 0.0005\n",
      "Variable:                  130 Importance: 0.0005\n",
      "Variable:                  132 Importance: 0.0005\n",
      "Variable:                  141 Importance: 0.0005\n",
      "Variable:                  142 Importance: 0.0005\n",
      "Variable:                  143 Importance: 0.0005\n",
      "Variable:                  160 Importance: 0.0005\n",
      "Variable: curr_team_1610612738 Importance: 0.0004\n",
      "Variable: curr_team_1610612751 Importance: 0.0004\n",
      "Variable: curr_team_1610612757 Importance: 0.0004\n",
      "Variable: curr_team_1610612762 Importance: 0.0004\n",
      "Variable: curr_team_1610612763 Importance: 0.0004\n",
      "Variable: curr_team_1610612765 Importance: 0.0004\n",
      "Variable:                    0 Importance: 0.0004\n",
      "Variable:                    5 Importance: 0.0004\n",
      "Variable:                   10 Importance: 0.0004\n",
      "Variable:                   11 Importance: 0.0004\n",
      "Variable:                   26 Importance: 0.0004\n",
      "Variable:                   48 Importance: 0.0004\n",
      "Variable:                   59 Importance: 0.0004\n",
      "Variable:                   62 Importance: 0.0004\n",
      "Variable:                   63 Importance: 0.0004\n",
      "Variable:                   67 Importance: 0.0004\n",
      "Variable:                   72 Importance: 0.0004\n",
      "Variable:                   81 Importance: 0.0004\n",
      "Variable:                   82 Importance: 0.0004\n",
      "Variable:                   88 Importance: 0.0004\n",
      "Variable:                   92 Importance: 0.0004\n",
      "Variable:                   94 Importance: 0.0004\n",
      "Variable:                   95 Importance: 0.0004\n",
      "Variable:                   98 Importance: 0.0004\n",
      "Variable:                   99 Importance: 0.0004\n",
      "Variable:                  103 Importance: 0.0004\n",
      "Variable:                  109 Importance: 0.0004\n",
      "Variable:                  113 Importance: 0.0004\n",
      "Variable:                  116 Importance: 0.0004\n",
      "Variable:                  127 Importance: 0.0004\n",
      "Variable:                  133 Importance: 0.0004\n",
      "Variable:                  134 Importance: 0.0004\n",
      "Variable:                  138 Importance: 0.0004\n",
      "Variable:                  145 Importance: 0.0004\n",
      "Variable:                  153 Importance: 0.0004\n",
      "Variable:                  159 Importance: 0.0004\n",
      "Variable: curr_team_1610612758 Importance: 0.0003\n",
      "Variable: curr_team_1610612760 Importance: 0.0003\n",
      "Variable: curr_team_1610612764 Importance: 0.0003\n",
      "Variable:                    3 Importance: 0.0003\n",
      "Variable:                    6 Importance: 0.0003\n",
      "Variable:                   16 Importance: 0.0003\n",
      "Variable:                   17 Importance: 0.0003\n",
      "Variable:                   19 Importance: 0.0003\n",
      "Variable:                   21 Importance: 0.0003\n",
      "Variable:                   23 Importance: 0.0003\n",
      "Variable:                   30 Importance: 0.0003\n",
      "Variable:                   36 Importance: 0.0003\n",
      "Variable:                   38 Importance: 0.0003\n",
      "Variable:                   39 Importance: 0.0003\n",
      "Variable:                   50 Importance: 0.0003\n",
      "Variable:                   55 Importance: 0.0003\n",
      "Variable:                   65 Importance: 0.0003\n",
      "Variable:                   78 Importance: 0.0003\n",
      "Variable:                   83 Importance: 0.0003\n",
      "Variable:                   96 Importance: 0.0003\n",
      "Variable:                   97 Importance: 0.0003\n",
      "Variable:                  102 Importance: 0.0003\n",
      "Variable:                  106 Importance: 0.0003\n",
      "Variable:                  122 Importance: 0.0003\n",
      "Variable:                  123 Importance: 0.0003\n",
      "Variable:                  136 Importance: 0.0003\n",
      "Variable:                  139 Importance: 0.0003\n",
      "Variable:                  144 Importance: 0.0003\n",
      "Variable:                  148 Importance: 0.0003\n",
      "Variable:                  156 Importance: 0.0003\n",
      "Variable:                  161 Importance: 0.0003\n",
      "Variable:                  163 Importance: 0.0003\n",
      "Variable:                  170 Importance: 0.0003\n",
      "Variable:                  172 Importance: 0.0003\n",
      "Variable:                  176 Importance: 0.0003\n",
      "Variable: curr_team_1610612740 Importance: 0.0002\n",
      "Variable: curr_team_1610612759 Importance: 0.0002\n",
      "Variable:                    7 Importance: 0.0002\n",
      "Variable:                    9 Importance: 0.0002\n",
      "Variable:                   29 Importance: 0.0002\n",
      "Variable:                   34 Importance: 0.0002\n",
      "Variable:                   37 Importance: 0.0002\n",
      "Variable:                   40 Importance: 0.0002\n",
      "Variable:                   42 Importance: 0.0002\n",
      "Variable:                   61 Importance: 0.0002\n",
      "Variable:                   86 Importance: 0.0002\n",
      "Variable:                  105 Importance: 0.0002\n",
      "Variable:                  120 Importance: 0.0002\n",
      "Variable:                  126 Importance: 0.0002\n",
      "Variable:                  149 Importance: 0.0002\n",
      "Variable:                  164 Importance: 0.0002\n",
      "Variable:                  171 Importance: 0.0002\n",
      "Variable:                  173 Importance: 0.0002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "#scale the X variables\n",
    "X = large_df_of_sequences.loc[:, large_df_of_sequences.columns != 'Y']\n",
    "saved_columns = X.columns\n",
    "x = X.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "X = pd.DataFrame(x_scaled, columns=saved_columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Y = large_df_of_sequences['Y']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=10)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=1000, random_state=1)\n",
    "rf.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - y_test)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / y_test)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')\n",
    "    \n",
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 4)) for feature, importance in zip(X.columns, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];    \n",
    "\n",
    "y_predict = rf.predict(x_test)\n",
    "# print (\"R2 score:\",r2_score(y_test,y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:  4.7min remaining:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'bootstrap': True, 'max_depth': 150, 'max_features': 100, 'min_samples_leaf': 3, 'min_samples_split': 12, 'n_estimators': 500}\n",
      "Detailed classification report:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier , RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create param grid.\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [150],\n",
    "    'max_features': [200,100],\n",
    "    'min_samples_leaf': [3],\n",
    "    'min_samples_split': [ 3,6,12],\n",
    "    'n_estimators': [500]\n",
    "}\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "best_clf = clf.fit(x_train, y_train)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(best_clf.best_params_)\n",
    "print(\"Detailed classification report:\")\n",
    "y_true, y_pred = y_test, best_clf.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.13269282706603902\n",
      "Best Score: 0.10099068623482245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def RFR(X_train, X_test, y_train, y_test, best_params):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    estimator = RandomForestRegressor(n_jobs=-1).set_params(**best_params)\n",
    "    estimator.fit(X_train,y_train)\n",
    "    y_predict = estimator.predict(X_test)\n",
    "    print (\"R2 score:\",r2_score(y_test,y_predict))\n",
    "    return y_test,y_predict\n",
    "\n",
    "\n",
    "# best_score, best_params = Grid_Search_CV_RFR(X_train, y_train)\n",
    "y_test , y_predict = RFR(x_train, x_test, y_train, y_test ,best_clf.best_params_ )\n",
    "print (\"Best Score:\" ,best_clf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename_pm = 'Plus_Minus_2018-11-01_2020-02-04_5Days.sav'\n",
    "pickle.dump(best_clf, open(filename_pm,'wb'))\n",
    "best_clf = pickle.load(open(filename_pm, 'rb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_game_score(\n",
    "                        curr_team_abv,\n",
    "                        opp_team,\n",
    "                        is_current_game_at_home,\n",
    "                        curr_team_id,\n",
    "                        df_g,\n",
    "                        df,\n",
    "                        pbp,\n",
    "                        shot_chart_df\n",
    "                        ):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    x = df_g[df_g['TEAM_ID'] == curr_team_id].sort_values('GAME_DATE').reset_index(drop=True)\n",
    "    tmp = x[-sliding_window_num_of_games:]\n",
    "\n",
    "    dummy_curr_team = pd.get_dummies(x['TEAM_ID'], prefix ='team').reindex(columns = dummy_nba_teams.columns, fill_value=0)\n",
    "    dummy_curr_team.columns = ['curr_' + col for col in dummy_curr_team.columns]\n",
    "    team_indicator = dummy_curr_team.loc[0].values\n",
    "\n",
    "    list_of_sequence_of_wins = list(tmp['IsWin'].values)\n",
    "    new_cols = []\n",
    "    for game in range(sliding_window_num_of_games):\n",
    "            new_cols.insert(0,'{}_games_back_IsWin'.format(game + 1))\n",
    "    df_of_sequence_of_wins = pd.DataFrame([list_of_sequence_of_wins],columns=new_cols)\n",
    "\n",
    "    # # get team indicator\n",
    "    team_indicator = dummy_curr_team[0:1]\n",
    "    team_indicator\n",
    "\n",
    "    # is at home\n",
    "    list_of_sequence_of_at_home = list(tmp['IsHome'].values)\n",
    "    new_cols = []\n",
    "    for game in range(sliding_window_num_of_games):\n",
    "            new_cols.insert(0,'{}_games_back_IsHome'.format(game + 1))\n",
    "    df_of_sequence_of_at_home = pd.DataFrame([list_of_sequence_of_at_home],columns=new_cols)\n",
    "    df_of_sequence_of_at_home['{}_games_back_IsHome'.format(sliding_window_num_of_games+1)] = is_current_game_at_home\n",
    "\n",
    "\n",
    "    # get opp team indicator \n",
    "\n",
    "    opp_dummy_teams = pd.get_dummies(tmp['Opposing_team_ID'].astype(int).append(pd.Series(opp_team_id)), prefix ='team').reindex(columns = dummy_nba_teams.columns, fill_value=0)\n",
    "    opp_dummy_teams.columns = ['opp_' + col for col in opp_dummy_teams.columns]\n",
    "    appended_list_of_encoded_opp_teams = list(itertools.chain(*opp_dummy_teams.values))\n",
    "    appended_df_of_encoded_opp_teams = pd.DataFrame([appended_list_of_encoded_opp_teams])\n",
    "\n",
    "    # add averages of categories\n",
    "    cols_to_calc = ['PTS','REB','AST','STL','BLK','TOV','PLUS_MINUS','FG3_PCT','FG_PCT','FT_PCT','num_of_possessions',\n",
    "                       'AdjustedPM','OffRating','EFG','AST_ratio','Opp_points','Def_Rating']\n",
    "    averages_of_categories_curr_team = tmp[cols_to_calc].mean().values\n",
    "    df_of_averages_of_categories_curr_team = pd.DataFrame([averages_of_categories_curr_team],columns=cols_to_calc)\n",
    "    df_of_averages_of_categories_curr_team\n",
    "\n",
    "    # add shot area avgs for curr team\n",
    "    shot_index= ['Mid-Range', 'In The Paint (Non-RA)', 'Restricted Area',\n",
    "    'Above the Break 3', 'Left Corner 3', 'Right Corner 3']\n",
    "\n",
    "    shot_chart_df_for_tmp = shot_chart_df[(shot_chart_df['GAME_ID'].isin(tmp['GAME_ID'].values))&\n",
    "                             (shot_chart_df['TEAM_ID']==curr_team_id)].groupby(\n",
    "                                ['SHOT_ZONE_BASIC']).mean()['SHOT_MADE_FLAG'].reset_index()\n",
    "    shot_chart_df_for_tmp_reindex = shot_chart_df_for_tmp[['SHOT_ZONE_BASIC','SHOT_MADE_FLAG']].set_index('SHOT_ZONE_BASIC').reindex(shot_index).fillna(0)\n",
    "    shot_area_avgs = shot_chart_df_for_tmp_reindex.T.reset_index(drop=True)\n",
    "    shot_area_avgs\n",
    "\n",
    "    # add shot chart of opposing teams during window\n",
    "    shot_chart_df_for_tmp = shot_chart_df[(shot_chart_df['GAME_ID'].isin(tmp[:-1]['GAME_ID'].values))&\n",
    "                             (shot_chart_df['TEAM_ID']!=curr_team_id)].groupby(\n",
    "                                ['SHOT_ZONE_BASIC']).mean()['SHOT_MADE_FLAG'].reset_index()\n",
    "    shot_chart_df_for_tmp_reindex = shot_chart_df_for_tmp[['SHOT_ZONE_BASIC','SHOT_MADE_FLAG']].set_index('SHOT_ZONE_BASIC').reindex(shot_index).fillna(0)\n",
    "    shot_area_avgs_opp = shot_chart_df_for_tmp_reindex.T.reset_index(drop=True)\n",
    "    shot_area_avgs_opp\n",
    "    \n",
    "    \n",
    "    # add sequence of scores\n",
    "    list_of_sequence_of_wins = list(tmp['PTS'].values)\n",
    "    new_cols = []\n",
    "    for game in range(sliding_window_num_of_games):\n",
    "            new_cols.insert(0,'{}_games_back_PTS'.format(game + 1))\n",
    "    df_of_sequence_of_scores = pd.DataFrame([list_of_sequence_of_wins],columns=new_cols)\n",
    "\n",
    "        \n",
    "     # add averages of categories\n",
    "    x_opp = df_g[df_g['TEAM_ID'] == opp_team_id].sort_values('GAME_DATE').reset_index(drop=True)\n",
    "    tmp_opp = x_opp[-sliding_window_num_of_games:]\n",
    "    cols_to_calc = ['PTS','REB','AST','STL','BLK','TOV','PLUS_MINUS','FG3_PCT','FG_PCT','FT_PCT','num_of_possessions',\n",
    "                       'AdjustedPM','OffRating','EFG','AST_ratio','Opp_points','Def_Rating']\n",
    "    averages_of_categories_opp_team = tmp_opp[cols_to_calc].mean().values\n",
    "    df_of_averages_of_categories_opp_team = pd.DataFrame([averages_of_categories_opp_team],columns=cols_to_calc)\n",
    "    df_of_averages_of_categories_opp_team\n",
    "    \n",
    "    # add sequence of pms\n",
    "    list_of_sequence_of_pm = list(tmp['PLUS_MINUS'].values)\n",
    "    new_cols = []\n",
    "    for game in range(sliding_window_num_of_games):\n",
    "            new_cols.insert(0,'{}_games_back_Plusminus'.format(game + 1))\n",
    "    df_of_sequence_of_plusminus = pd.DataFrame([list_of_sequence_of_pm],columns=new_cols)\n",
    "\n",
    "   # add sequence of days between games\n",
    "    tmp_days_back = x[-sliding_window_num_of_games-1:]\n",
    "    l = tmp_days_back['GAME_DATE'].diff().dt.days.dropna().values\n",
    "    l = [4 if sl >4 else sl for sl in l]\n",
    "    new_cols = []\n",
    "    for game in range(sliding_window_num_of_games):\n",
    "            new_cols.insert(0,'{}_games_back_PTS'.format(game + 1))\n",
    "    df_days_between = pd.DataFrame([l],columns=new_cols)\n",
    "\n",
    "\n",
    "    # start merging all together \n",
    "    # 1. wins\n",
    "    # 2. team indicator\n",
    "    # 3. at home indicator\n",
    "    # 4. TOV sequence\n",
    "    # print(len(team_indicator.columns),'team_indicator')\n",
    "    # print(len(df_of_sequence_of_wins.columns),'df_of_sequence_of_wins')\n",
    "    # print(len(df_of_sequence_of_at_home.columns),'df_of_sequence_of_at_home')\n",
    "    # print(len(appended_df_of_encoded_opp_teams.columns),'appended_df_of_encoded_opp_teams')\n",
    "    # print(len(df_of_averages_of_categories_curr_team.columns),'df_of_averages_of_categories_curr_team')\n",
    "    # print(len(shot_area_avgs.columns),'shot_area_avgs')\n",
    "    # print(len(shot_area_avgs_opp.columns),'shot_area_avgs_opp')\n",
    "    df_all_features = team_indicator.merge(df_of_sequence_of_wins , how='inner' , left_index=True , right_index=True)\n",
    "    df_all_features = df_all_features.merge(df_of_sequence_of_at_home, how='inner' , left_index=True , right_index=True)\n",
    "    df_all_features = df_all_features.merge(appended_df_of_encoded_opp_teams, how='inner' , left_index=True , right_index=True)\n",
    "    df_all_features = df_all_features.merge(df_of_averages_of_categories_curr_team, how='inner' , left_index=True , right_index=True)\n",
    "    df_all_features = df_all_features.merge(shot_area_avgs, how='inner' , left_index=True , right_index=True)\n",
    "    df_all_features = df_all_features.merge(shot_area_avgs_opp, how='inner' , left_index=True , right_index=True)\n",
    "    df_all_features = df_all_features.merge(df_of_sequence_of_scores, how='inner' , left_index=True , right_index=True)\n",
    "    df_all_features = df_all_features.merge(df_of_averages_of_categories_opp_team, how='inner' , left_index=True , right_index=True)\n",
    "    df_all_features = df_all_features.merge(df_of_sequence_of_plusminus, how='inner' , left_index=True , right_index=True)\n",
    "    df_all_features = df_all_features.merge(df_days_between, how='inner' , left_index=True , right_index=True)\n",
    "\n",
    "    len(df_all_features.columns)\n",
    "    df_all_features = df_all_features[X.columns]\n",
    "#     df_all_features = df_all_features.loc[:, df_all_features.columns != 'Y']\n",
    "    df_all_features = pd.DataFrame(min_max_scaler.transform(df_all_features),columns=df_all_features.columns)\n",
    "    \n",
    "#     len(X.columns)\n",
    "\n",
    "    print([curr_team_abv,'------->' , best_clf.predict(df_all_features) , '-------',\n",
    "                        opp_team,\n",
    "                        is_current_game_at_home,\n",
    "                        curr_team_id])\n",
    "    print()\n",
    "    results_saved = [single_date,curr_team_abv, best_clf.predict(df_all_features)[0] ,\n",
    "                        opp_team,\n",
    "                        is_current_game_at_home,\n",
    "                        curr_team_id]\n",
    "    return results_saved\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "2020-02-12T00:00:00.000000000\n",
      "done\n",
      "['DEN', 'LAL']\n",
      "['DEN', 'LAL']\n",
      "2020-02-11 00:00:00\n",
      "['DEN', '------->', array([8.2196724]), '-------', 'LAL', 1, 1610612743]\n",
      "\n",
      "['ORL', 'DET']\n",
      "['ORL', 'DET']\n",
      "2020-02-11 00:00:00\n",
      "['ORL', '------->', array([-3.70271706]), '-------', 'DET', 1, 1610612753]\n",
      "\n",
      "['CLE', 'ATL']\n",
      "['CLE', 'ATL']\n",
      "2020-02-11 00:00:00\n",
      "['CLE', '------->', array([-6.15693976]), '-------', 'ATL', 1, 1610612739]\n",
      "\n",
      "['UTA', 'MIA']\n",
      "['UTA', 'MIA']\n",
      "2020-02-11 00:00:00\n",
      "['UTA', '------->', array([-6.91868551]), '-------', 'MIA', 1, 1610612762]\n",
      "\n",
      "['NYK', 'WAS']\n",
      "['NYK', 'WAS']\n",
      "2020-02-11 00:00:00\n",
      "['NYK', '------->', array([-3.44918713]), '-------', 'WAS', 1, 1610612752]\n",
      "\n",
      "['MIN', 'CHA']\n",
      "['MIN', 'CHA']\n",
      "2020-02-11 00:00:00\n",
      "['MIN', '------->', array([-3.7500371]), '-------', 'CHA', 1, 1610612750]\n",
      "\n",
      "['BKN', 'TOR']\n",
      "['BKN', 'TOR']\n",
      "2020-02-11 00:00:00\n",
      "['BKN', '------->', array([-0.49984818]), '-------', 'TOR', 1, 1610612751]\n",
      "\n",
      "['MEM', 'POR']\n",
      "['MEM', 'POR']\n",
      "2020-02-11 00:00:00\n",
      "['MEM', '------->', array([-0.91645078]), '-------', 'POR', 1, 1610612763]\n",
      "\n",
      "['DAL', 'SAC']\n",
      "['DAL', 'SAC']\n",
      "2020-02-11 00:00:00\n",
      "['DAL', '------->', array([2.12100736]), '-------', 'SAC', 1, 1610612742]\n",
      "\n",
      "['PHX', 'GSW']\n",
      "['PHX', 'GSW']\n",
      "2020-02-11 00:00:00\n",
      "['PHX', '------->', array([-4.34728181]), '-------', 'GSW', 1, 1610612756]\n",
      "\n",
      "['IND', 'MIL']\n",
      "['IND', 'MIL']\n",
      "2020-02-11 00:00:00\n",
      "['IND', '------->', array([-3.51776584]), '-------', 'MIL', 1, 1610612754]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lsit_of_games = [\n",
    "#                 ['TOR','POR'] , \n",
    "#                 ['CLE','DET'] , \n",
    "#                 ['BKN','OKC'] , \n",
    "#                 ['MEM','MIN'] , \n",
    "#                 ['PHX','SAC'] , \n",
    "#                 ['LAL','NYK'] , \n",
    "                \n",
    "#             ]\n",
    "\n",
    "# df,df_g,pbp,shot_chart_df,team_abv_to_id_mapping = load_dfs( MAX_DATE = '2020-01-07')\n",
    "\n",
    "total_results_saved = []\n",
    "\n",
    "FIRST_DATE_TO_CHECK = '2020-02-11'\n",
    "LAST_DATE_TO_RUN_ON = '2020-02-13'\n",
    "\n",
    "\n",
    "\n",
    "df,df_g_global ,pbp,shot_chart_df,team_abv_to_id_mapping = load_dfs( MAX_DATE = LAST_DATE_TO_RUN_ON)\n",
    "\n",
    "list_of_games_to_check = df_g_global[['GAME_DATE','TEAM_ABBREVIATION','GAME_ID','IsHome']]\n",
    "len(list_of_games_to_check)\n",
    "merged_list_of_games_to_check = list_of_games_to_check.merge(list_of_games_to_check,\n",
    "                                                             how='inner',\n",
    "                                                             left_on =['GAME_ID'] ,\n",
    "                                                             right_on =['GAME_ID'])\n",
    "merged_list_of_games_to_check = merged_list_of_games_to_check[merged_list_of_games_to_check['TEAM_ABBREVIATION_x']!= merged_list_of_games_to_check['TEAM_ABBREVIATION_y']]\n",
    "merged_list_of_games_to_check=merged_list_of_games_to_check[merged_list_of_games_to_check['IsHome_x']==1]\n",
    "\n",
    "\n",
    "merged_list_of_games_to_check = merged_list_of_games_to_check[merged_list_of_games_to_check['GAME_DATE_x']>FIRST_DATE_TO_CHECK]\n",
    "list_of_dates = merged_list_of_games_to_check['GAME_DATE_x'].unique()\n",
    "for single_date in list_of_dates:\n",
    "    print (single_date)\n",
    "    lsit_of_games = []\n",
    "    for ix,row in merged_list_of_games_to_check[merged_list_of_games_to_check['GAME_DATE_x']==single_date].iterrows():\n",
    "        merged_list_of_games_to_check.iloc[1]\n",
    "        game=[row['TEAM_ABBREVIATION_x'],row['TEAM_ABBREVIATION_y']]\n",
    "        lsit_of_games.append(game)\n",
    "    df,df_g,pbp,shot_chart_df,team_abv_to_id_mapping = load_dfs( MAX_DATE = str(single_date)[:10])\n",
    "           \n",
    "        \n",
    "        \n",
    "    \n",
    "    sliding_window_num_of_games = 5\n",
    "\n",
    "    for game in lsit_of_games:\n",
    "        print(game)\n",
    "    #     print(df_g['GAME_DATE'].max())\n",
    "    #     df_g['TEAM_ABBREVIATION'].unique()\n",
    "        print(game)\n",
    "        print(df_g['GAME_DATE'].max())\n",
    "        df_g['TEAM_ABBREVIATION'].unique()\n",
    "        ###########################\n",
    "        ### DEFINE YOUR TEAMS   ###\n",
    "        ###########################\n",
    "        curr_team_abv = game[0] #'PHX'\n",
    "        curr_team_id = team_abv_to_id_mapping[curr_team_abv]\n",
    "\n",
    "        opp_team = game[1] #'SAC'\n",
    "        opp_team_id  = team_abv_to_id_mapping[opp_team]\n",
    "        is_current_game_at_home = 1\n",
    "\n",
    "\n",
    "\n",
    "        ###########################\n",
    "\n",
    "\n",
    "        results_saved = predict_game_score(\n",
    "                            curr_team_abv,\n",
    "                           opp_team,\n",
    "                           1,\n",
    "                           curr_team_id ,\n",
    "                          df_g,\n",
    "                          df,\n",
    "                          pbp,\n",
    "                          shot_chart_df\n",
    "                            )\n",
    "        total_results_saved.append(results_saved)\n",
    "#     predict_game_score(\n",
    "#                         opp_team,\n",
    "#                        curr_team_abv,\n",
    "#                        0,\n",
    "#                        opp_team_id,\n",
    "#                       df_g,\n",
    "#                       df,\n",
    "#                       pbp,\n",
    "#                       shot_chart_df,\n",
    "#                     X.columns)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(total_results_saved, columns=['Date','HomeTeam', 'OutcomePM', 'AwayTeam' , 'IsHome' , 'HomeTeamID' ]).to_csv('~/pm_Jan.csv',index=False, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "['BOS', 'LAC']\n",
      "['BOS', 'LAC']\n",
      "2020-02-12 00:00:00\n",
      "['BOS', '------->', array([0.37981542]), '-------', 'LAC', 1, 1610612738]\n",
      "\n",
      "['NOP', 'OKC']\n",
      "['NOP', 'OKC']\n",
      "2020-02-12 00:00:00\n",
      "['NOP', '------->', array([0.30641058]), '-------', 'OKC', 1, 1610612740]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# RUN PREDICTED\n",
    "################\n",
    "# LAST_DATE_TO_RUN_ON = '2020-02-20'\n",
    "single_date =  '2020-02-13'\n",
    "LAST_DATE_TO_RUN_ON = '2020-02-13'\n",
    "\n",
    "df,df_g_global ,pbp,shot_chart_df,team_abv_to_id_mapping = load_dfs( MAX_DATE = LAST_DATE_TO_RUN_ON)\n",
    "           \n",
    "lsit_of_games = [\n",
    "['BOS','LAC'],\n",
    "['NOP','OKC'],\n",
    "]\n",
    "\n",
    "\n",
    "sliding_window_num_of_games = 5\n",
    "\n",
    "for game in lsit_of_games:\n",
    "    print(game)\n",
    "#     print(df_g['GAME_DATE'].max())\n",
    "#     df_g['TEAM_ABBREVIATION'].unique()\n",
    "    print(game)\n",
    "    print(df_g_global['GAME_DATE'].max())\n",
    "    df_g['TEAM_ABBREVIATION'].unique()\n",
    "    ###########################\n",
    "    ### DEFINE YOUR TEAMS   ###\n",
    "    ###########################\n",
    "    curr_team_abv = game[0] #'PHX'\n",
    "    curr_team_id = team_abv_to_id_mapping[curr_team_abv]\n",
    "\n",
    "    opp_team = game[1] #'SAC'\n",
    "    opp_team_id  = team_abv_to_id_mapping[opp_team]\n",
    "    is_current_game_at_home = 1\n",
    "\n",
    "\n",
    "\n",
    "    ###########################\n",
    "\n",
    "\n",
    "    predict_game_score(\n",
    "                        curr_team_abv,\n",
    "                       opp_team,\n",
    "                       1,\n",
    "                       curr_team_id ,\n",
    "                      df_g_global,\n",
    "                      df,\n",
    "                      pbp,\n",
    "                      shot_chart_df)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>OutcomePM</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>IsHome</th>\n",
       "      <th>HomeTeamID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>IND</td>\n",
       "      <td>6.432246</td>\n",
       "      <td>NYK</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>ORL</td>\n",
       "      <td>1.714237</td>\n",
       "      <td>MIA</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>LAC</td>\n",
       "      <td>2.919397</td>\n",
       "      <td>MIN</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>SAS</td>\n",
       "      <td>6.028633</td>\n",
       "      <td>CHA</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>WAS</td>\n",
       "      <td>-0.697588</td>\n",
       "      <td>BKN</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>POR</td>\n",
       "      <td>3.808655</td>\n",
       "      <td>UTA</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>DAL</td>\n",
       "      <td>0.055496</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>SAC</td>\n",
       "      <td>-2.411292</td>\n",
       "      <td>LAL</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>CLE</td>\n",
       "      <td>-7.263380</td>\n",
       "      <td>GSW</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>BOS</td>\n",
       "      <td>4.597735</td>\n",
       "      <td>PHI</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>DET</td>\n",
       "      <td>-3.950859</td>\n",
       "      <td>TOR</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>MIL</td>\n",
       "      <td>7.504133</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>PHX</td>\n",
       "      <td>-1.201563</td>\n",
       "      <td>OKC</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>NOP</td>\n",
       "      <td>-0.360462</td>\n",
       "      <td>MEM</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>BKN</td>\n",
       "      <td>-2.180000</td>\n",
       "      <td>CHI</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>LAL</td>\n",
       "      <td>-1.131614</td>\n",
       "      <td>POR</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>HOU</td>\n",
       "      <td>-2.406137</td>\n",
       "      <td>DAL</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>LAC</td>\n",
       "      <td>-2.722768</td>\n",
       "      <td>SAC</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>CLE</td>\n",
       "      <td>-6.080557</td>\n",
       "      <td>TOR</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>DEN</td>\n",
       "      <td>-2.519464</td>\n",
       "      <td>UTA</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>BOS</td>\n",
       "      <td>3.528063</td>\n",
       "      <td>GSW</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>WAS</td>\n",
       "      <td>-2.407520</td>\n",
       "      <td>CHA</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>ATL</td>\n",
       "      <td>-5.715127</td>\n",
       "      <td>PHI</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date HomeTeam  OutcomePM AwayTeam  IsHome  HomeTeamID\n",
       "0  2020-02-01      IND   6.432246      NYK       1  1610612754\n",
       "1  2020-02-01      ORL   1.714237      MIA       1  1610612753\n",
       "2  2020-02-01      LAC   2.919397      MIN       1  1610612746\n",
       "3  2020-02-01      SAS   6.028633      CHA       1  1610612759\n",
       "4  2020-02-01      WAS  -0.697588      BKN       1  1610612764\n",
       "5  2020-02-01      POR   3.808655      UTA       1  1610612757\n",
       "6  2020-02-01      DAL   0.055496      ATL       1  1610612742\n",
       "7  2020-02-01      SAC  -2.411292      LAL       1  1610612758\n",
       "8  2020-02-01      CLE  -7.263380      GSW       1  1610612739\n",
       "9  2020-02-01      BOS   4.597735      PHI       1  1610612738\n",
       "10 2020-01-31      DET  -3.950859      TOR       1  1610612765\n",
       "11 2020-01-31      MIL   7.504133      DEN       1  1610612749\n",
       "12 2020-01-31      PHX  -1.201563      OKC       1  1610612756\n",
       "13 2020-01-31      NOP  -0.360462      MEM       1  1610612740\n",
       "14 2020-01-31      BKN  -2.180000      CHI       1  1610612751\n",
       "15 2020-01-31      LAL  -1.131614      POR       1  1610612747\n",
       "16 2020-01-31      HOU  -2.406137      DAL       1  1610612745\n",
       "17 2020-01-30      LAC  -2.722768      SAC       1  1610612746\n",
       "18 2020-01-30      CLE  -6.080557      TOR       1  1610612739\n",
       "19 2020-01-30      DEN  -2.519464      UTA       1  1610612743\n",
       "20 2020-01-30      BOS   3.528063      GSW       1  1610612738\n",
       "21 2020-01-30      WAS  -2.407520      CHA       1  1610612764\n",
       "22 2020-01-30      ATL  -5.715127      PHI       1  1610612737"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(total_results_saved, columns=['Date','HomeTeam', 'OutcomePM', 'AwayTeam' , 'IsHome' , 'HomeTeamID' ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
